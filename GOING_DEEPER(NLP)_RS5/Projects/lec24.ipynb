{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **24. HuggingFace 커스텀 프로젝트 만들기 [프로젝트]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **24-1. 프로젝트 : 커스텀 프로젝트 직접 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 코드에서 수행해 본 내용을 토대로, 이번에는 한국어 데이터셋에 도전해보겠습니다.\n",
    "<br><br>\n",
    "앞서 본 GLUE benchmark의 한국어 버전 [KLUE benchmark](https://klue-benchmark.com/)를 들어보신 적 있나요?\n",
    "<br><br>\n",
    "GLUE와 마찬가지로 한국어 자연어처리에 대한 이해도를 높이기 위해 만들어진 데이터셋 benchmark입니다. 총 8가지의 데이터셋이 있습니다. 다만 이번 시간에 진행할 프로젝트는 KLUE의 dataset을 활용하는 것이 아닌, model(klue/ber-base)를 활용하여 NSMC(Naver Sentiment Movie Corpus) task를 도전해보겠습니다.\n",
    "<br><br>\n",
    "모델과 데이터에 관한 정보는 링크를 참조해주세요.\n",
    "\n",
    "- [KLUE/Bert-base](https://huggingface.co/klue/bert-base)\n",
    "- [NSMC](https://github.com/e9t/nsmc)\n",
    "\n",
    "준비가 되셨다면 아래와 같은 순서로 진행해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **라이브러리 버전을 확인해 봅니다.**\n",
    "\n",
    "---\n",
    "\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import transformers\n",
    "import datasets\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP 1. `NSMC` 데이터 분석 및 Huggingface dataset 구성**\n",
    "\n",
    "---\n",
    "\n",
    "데이터셋은 깃허브에서 다운받거나, [Huggingface datasets](https://huggingface.co/datasets)에서 가져올 수 있습니다. 앞에서 배운 방법들을 활용해봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP 2. klue/bert-base model 및 tokenizer 불러오기**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP 3. 위에서 불러온 tokenizer으로 데이터셋을 전처리하고, model 학습 진행해 보기**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP 4. Fine-tuning을 통하여 모델 성능(accuarcy) 향상시키기**\n",
    "- 데이터 전처리, `TrainingArguments` 등을 조정하여 모델의 정확도를 90% 이상으로 끌어올려봅시다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **STEP 5. Bucketing을 적용하여 학습시키고, STEP 4의 결과와의 비교**\n",
    "\n",
    "- 아래 링크를 바탕으로 bucketing과 dynamic padding이 무엇인지 알아보고, 이들을 적용하여 model을 학습시킵니다.\n",
    "\n",
    "    - [Data Collator](https://huggingface.co/docs/transformers/v4.30.0/en/main_classes/data_collator)\n",
    "\n",
    "    - [Trainer.TrainingArguments 의 `group_by_length`](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)\n",
    "\n",
    "- STEP 4에 학습한 결과와 bucketing을 적용하여 학습시킨 결과를 비교해보고, 모델 성능 향상과 훈련 시간 두 가지 측면에서 각각 어떤 이점이 있는지 비교해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **24-2. 프로젝트 제출**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **루브릭**\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|평가문항|상세기준|\n",
    "|--|--|\n",
    "|1. 모델과 데이터를 정상적으로 불러오고, 작동하는 것을 확인하였다.|klue/bert-base를 NSMC 데이터셋으로 fine-tuning 하여, 모델이 정상적으로 작동하는 것을 확인하였다.|\n",
    "|2. Preprocessing을 개선하고, fine-tuning을 통해 모델의 성능을 개선시켰다.|Validation accuracy를 90% 이상으로 개선하였다.|\n",
    "|3. 모델 학습에 Bucketing을 성공적으로 적용하고, 그 결과를 비교분석하였다.|Bucketing task을 수행하여 fine-tuning 시 연산 속도와 모델 성능 간의 trade-off 관계가 발생하는지 여부를 확인하고, 분석한 결과를 제시하였다.|"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
