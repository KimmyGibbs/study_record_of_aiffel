{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **26. LLM Trend Note 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-1. 들어가며**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안녕하세요 여러분:) LLM Trend Note2에 오신 걸 환영합니다!<br>\n",
    "\n",
    "지난 노드에서 우리는 최신 LLM의 흐름을 살펴보면서<br>\n",
    "Foundation model의 조건과 Emergent Abilities의 특징에 대해 알아보았습니다.<br>\n",
    "그기저엔 대규모 분산 컴퓨팅 기술과<br>\n",
    "보다 혁신적인 모델 아키텍쳐 및 학습기법에 대한 고민이<br>\n",
    "단단한 기초를 이루고 있다는 사실도 함께 말이죠.<br>\n",
    "\n",
    "이번 노드에서는 RLHF를 간접적으로 구현한 언어모델에 한국어 말뭉치를 학습시켜보도록 하겠습니다.<br>\n",
    "이른바 KoChatGPT라고 할 수 있겠죠?<br>\n",
    "KoChatGPT를 구현한 레퍼런스 코드는 고우영님의 깃헙에서 참고했습니다.<br>\n",
    "\n",
    "그러면 몇 가지 퀴즈를 풀어보면서 함께 워밍업을 해보도록 할까요?<br>\n",
    "(퀴즈 정답은 깃헙의 리드미를 꼼꼼히 읽어보시면 찾으실 수 있습니다:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **KoChatGPT 구현을 위해 사용한 foundation model**\n",
    "    - [참고 Git](https://github.com/SKT-AI/KoGPT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **KoChatGPT에서 차용한 Reward Model, Proximal Policy Optimization 알고리즘의 출처**\n",
    "    > CollosalAI\n",
    "    - [RLHF Training Stage2 - Training reward model :](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat#RLHF-training-stage2---training-reward-model)\n",
    "    - [RLHF Training Stage3 - Training model with reinforcement learning by human feedback :](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat#RLHF-training-stage3---training-model-with-reinforcement-learning-by-human-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 스텝부터 본격적으로 코드실습을 진행하기에 앞서<br>\n",
    "KoChatGPT를 영상으로 소개한 자료도 함께 살펴보도록 하겠습니다.<br>\n",
    "\n",
    "[Video (실전) ChatGPT - replica 만들기 코드실습](https://youtu.be/Iq8erq62s8c)<br>\n",
    "\n",
    "**소스코드에 대한 설명**은 40:57부터 1:12:40 구간을 참고하세요.<br>\n",
    "**SFT**와 **RM** 그리고 **RLHF에 대한 내용을 복습**하고 싶으신 분들은 12:18부터 28:53 구간을 참고하세요.<br>\n",
    "\n",
    "영상을 다 시청하셨다면,<br>\n",
    "오늘 노드의 학습목표와 학습내용을 짚어보고<br>\n",
    "프로젝트를 향해 힘차게 달려가볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습목표**\n",
    "\n",
    "1. ChatGPT 구현을 위해 필요한 데이터셋의 종류 및 특징을 설명할 수 있습니다.\n",
    "\n",
    "2. Initial Model, Reward Model, RLHF Model의 학습 로직을 설명할 수 있습니다.\n",
    "\n",
    "3. KoChatGPT를 개선해 나만의 ChatGPT를 구현할 수 있습니다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습내용**\n",
    "\n",
    "1. Supervised Fine Tuning\n",
    "\n",
    "2. Reward Model의 ranking algorithm 및 loss fuction 설계 원리\n",
    "\n",
    "3. 언어모델을 강화학습하기 위한 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **준비물**\n",
    "\n",
    "LMS 클라우드 및 로컬 컴퓨터에서 진행할 경우 (우분투 20.04 기준) 아래와 같은 환경 및 라이브러리들이 요구됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Environment & Libraries**\n",
    "\n",
    "```shell\n",
    "#torch와 cuda 버전은 https://pytorch.kr/get-started/previous-versions/ 사이트를 참고해 \n",
    "#dependency를 맞춰 설치하시면 됩니다.\n",
    "wget https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda_11.6.0_510.39.01_linux.run\n",
    "sudo sh cuda_11.6.0_510.39.01_linux.run\n",
    "\n",
    "pip uninstall torch -y\n",
    "pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "\n",
    "pip install transformers==4.28.0\n",
    "pip install colossalai==0.2.7\n",
    "\n",
    "pip install openai\n",
    "pip install langchain==0.0.113\n",
    "pip install pandas>=1.4.1\n",
    "\n",
    "pip install --upgrade accelerate\n",
    "pip install bitsandbytes\n",
    "pip install loralib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 대부분은 컨테이너에 이미 설치가 되어 있지만<br>\n",
    "별도로 설치가 필요한 라이브러리가 있습니다.<br>\n",
    "\n",
    "**cloud shell에서 아래와 같이 KochatGPT를 설치해주세요. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "cd aiffel \n",
    "git clone https://github.com/airobotlab/KoChatGPT  \n",
    "cd KoChatGPT/colossalai_ChatGPT_230319/\n",
    "pip install .  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필수 requirement들이 잘 설치되어 있는지 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:1.12.1\n",
      "Cuda version: 11.3\n",
      "transformers                  4.28.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Torch version:{}\".format(torch.__version__)) # Torch version:1.12.1\n",
    "print(\"Cuda version: {}\".format(torch.version.cuda)) # Cuda version: 11.3\n",
    "!pip list | grep transformers # transformers 4.28.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-2. Base model and Dataset for RLHF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Trend Note1 노드에서 보았던<br>\n",
    "FLAN의 Instruction Tuning이나 PaLM의 Prompt Engineering 이 효과를 보기 위해선<br>\n",
    "언어모델의 입력을 단순한 query 형태로 주기보단<br>\n",
    "정교한 입력 시퀀스를 설계해야 한다고 배웠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예컨대, 작업의 지시사항이 담긴 instruction과<br>\n",
    "실제 모델이 작업 내용이 담긴 input,<br>\n",
    "그리고 CoT(Chain of thought) 형태의 예시답안 등을 prompt로 주는 식으로 말이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 이렇게 긴 prompt를 입력할 수 있으려면 그만한 모델 capacity가 뒷받침 되어야 합니다.<br>\n",
    "일단 수백에서 수천개의 token을 입력 벡터로 받아낼 수 있어야 하고,<br>\n",
    "각 토큰에 대한 충분한 셀프어텐션 연산이 가능한 트랜스포머 모듈이 쌓여야 하죠.<br>\n",
    "우리가 backbone 모델로 사용할 KoGPT-2의 성능을 잠시 확인해볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "허깅페이스의 transformers를 사용하면 토크나이저와 모델을 간단히 불러올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_name = \"skt/kogpt2-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 사용할 모델의 토크나이저가 입력받아 처리할 수 있는 최대 토큰 수를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt2': 1024,\n",
       " 'gpt2-medium': 1024,\n",
       " 'gpt2-large': 1024,\n",
       " 'gpt2-xl': 1024,\n",
       " 'distilgpt2': 1024}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.max_model_input_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kogpt-2는 어떻게 토크나이징을 하는지 잠시 확인해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(input_txt).tokens()\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>kogpt-2_tokens</th>\n",
       "      <td>▁바람</td>\n",
       "      <td>도</td>\n",
       "      <td>▁없는</td>\n",
       "      <td>▁공중에</td>\n",
       "      <td>▁수직</td>\n",
       "      <td>의</td>\n",
       "      <td>▁파</td>\n",
       "      <td>문을</td>\n",
       "      <td>▁내</td>\n",
       "      <td>이며</td>\n",
       "      <td>▁고</td>\n",
       "      <td>요</td>\n",
       "      <td>히</td>\n",
       "      <td>▁떨어지는</td>\n",
       "      <td>▁오동</td>\n",
       "      <td>잎은</td>\n",
       "      <td>▁누</td>\n",
       "      <td>구의</td>\n",
       "      <td>▁발자</td>\n",
       "      <td>취</td>\n",
       "      <td>▁입</td>\n",
       "      <td>니까</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input_IDs</th>\n",
       "      <td>10891</td>\n",
       "      <td>7235</td>\n",
       "      <td>9712</td>\n",
       "      <td>49207</td>\n",
       "      <td>14438</td>\n",
       "      <td>8143</td>\n",
       "      <td>9203</td>\n",
       "      <td>9941</td>\n",
       "      <td>9094</td>\n",
       "      <td>9639</td>\n",
       "      <td>9065</td>\n",
       "      <td>8084</td>\n",
       "      <td>8811</td>\n",
       "      <td>21215</td>\n",
       "      <td>34769</td>\n",
       "      <td>19985</td>\n",
       "      <td>9669</td>\n",
       "      <td>10139</td>\n",
       "      <td>21626</td>\n",
       "      <td>8408</td>\n",
       "      <td>9241</td>\n",
       "      <td>23775</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0     1     2      3      4     5     6     7     8     9   \\\n",
       "kogpt-2_tokens    ▁바람     도   ▁없는   ▁공중에    ▁수직     의    ▁파    문을    ▁내    이며   \n",
       "Input_IDs       10891  7235  9712  49207  14438  8143  9203  9941  9094  9639   \n",
       "\n",
       "                  10    11    12     13     14     15    16     17     18  \\\n",
       "kogpt-2_tokens    ▁고     요     히  ▁떨어지는    ▁오동     잎은    ▁누     구의    ▁발자   \n",
       "Input_IDs       9065  8084  8811  21215  34769  19985  9669  10139  21626   \n",
       "\n",
       "                  19    20     21   22  \n",
       "kogpt-2_tokens     취    ▁입     니까    .  \n",
       "Input_IDs       8408  9241  23775  389  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_columns = 40\n",
    "pd.options.display.max_rows = 60\n",
    "df = pd.DataFrame([tokens, input_ids[0]], index=[\"kogpt-2_tokens\", \"Input_IDs\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "내친 김에 디코딩 성능도 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.'\n",
      "\"그렇다면 그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리요?\"\n",
      "\"그건 무슨 소리\n"
     ]
    }
   ],
   "source": [
    "max_length=128\n",
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_greedy = model.generate(input_ids, max_length=max_length, do_sample=False)\n",
    "print(tokenizer.decode(output_greedy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시퀀스가 반복되어 출력되는군요.<br>\n",
    "그리디 서치 디코딩시 발견되는 전형적인 현상입니다.<br>\n",
    "\n",
    "이번엔 빔 서치 디코딩을 사용하고 n-gram 패널티까지 부과해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.'\n",
      "\"그렇지 않습니다.\"\n",
      "\"어떻게 된 일입니까?\"\n",
      "그녀는 고개를 갸웃거렸다.\n",
      "\"아니, 그게 무슨 말씀이신지 모르겠습니다만.\"\n",
      "\"무슨 말씀인지 알 수가 없군요.\"\n",
      "아무런 대답도 하지 않은 채 그녀는 고개를 끄덕였다.\n",
      "\"그래, 알았어.\"\n",
      "그녀의 눈에서 눈물이 주르륵 흘러내렸다.\n",
      "그녀가 다시 입을 열었다.\n",
      "\"정말 죄송합니다, 고마워요, 고맙습니다\"\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(input_txt, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=10, no_repeat_ngram_size=2,\n",
    "                             do_sample=False)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 시퀀스와 별 상관 없어 보이는 긴 문단이 생성됩니다.<br>\n",
    "그럼에도 생성된 문단은 제법 맥락을 갖춘 듯 보입니다.<br>\n",
    "하지만 문장 간의 정합성이나 일관성은 다소 떨어지는 부분도 관찰됩니다.<br>\n",
    "이번엔 샘플링 기법까지 추가해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까. 나는 내 발자취를 생각했다.\"\n",
      "\"그건 그렇지 않소. 그게 내가 알고 있었던 사실이오. 나도 그걸 몰랐다오.\"\n",
      "\"내가 어떻게 알았겠느냐고. 내게는 무슨 일인지 나도 알 수 있지요. 하지만 나는 그것을 알지 못한다지요.\"\n",
      "그러면서 그는 다시 입을 열었다.\n",
      "그때 갑자기 그녀의 얼굴이 창백해지더니 그의 손에 이끌려 사라져 버렸다.\n",
      "\"어떻게 된 일인가. 아니, 그건 알지도 못했소?\"\n",
      "그는 몸을 일으켰다.\n",
      "\"아직 내가 알 수가 없소.\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7, no_repeat_ngram_size=2,\n",
    "                             do_sample=True, temperature=2.0, top_k=50)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top_p 샘플링 기법도 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바람도 없는 공중에 수직의 파문을 내이며 고요히 떨어지는 오동잎은 누구의 발자취 입니까.\"\n",
      "\"그런데 그게 무슨 말입니까?\"\n",
      "그녀는 고개를 끄덕였다.\n",
      "\"무슨 말씀이십니까, 선생님.\"\n",
      "\"선생님, 저는 저를 사랑합니다만.\"\n",
      "그녀가 고개를 갸웃거리며 물었다.\n",
      "\"어떻게 그런 말씀을 하셨습니까? 선생님은 저에게 너무 많은 것을 주신 것 같습니다만, 선생님이 저희를 너무 사랑하셔서 그런 것입니다\"\n",
      "\"저도 선생님을 사랑하고 있습니다. 선생님의 사랑으로 저\n"
     ]
    }
   ],
   "source": [
    "output_beam = model.generate(input_ids, max_length=max_length, num_beams=7, no_repeat_ngram_size=2,\n",
    "                             do_sample=True, top_p=0.90)\n",
    "print(tokenizer.decode(output_beam[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최선의 디코딩 방법을 찾기 위해선<br>\n",
    "빔사이즈와 n-gram 패널티, temperature와 샘플링 인자로<br>\n",
    "조합할 수 있는 최선의 값을 찾아보는 실험이 필요합니다.<br>\n",
    "다양한 입력 시퀀스로 실험을 해보면 더 좋겠죠?<br>\n",
    "\n",
    "베이스라인 모델로 사용한 kogpt-2의 일반적인 성능을 확인해봤으니<br>\n",
    "구체적인 instruction과 prompting을 사용해 어떻게 디코딩을 해내는지도 확인해보세요.<br>\n",
    "RLHF를 적용하기 전의 실험값을 정리해보면<br>\n",
    "KoChatGPT의 성능 개선 여부를 확인하는데 도움이 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 사용하는 kogpt-2는 오리지널 GPT2의 가장 작은 버전입니다.\n",
    "하단의 이미지는 [GPT2](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)논문의 table-2 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf](../Images/lec_26/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "emergent abilities를 기대할 수 있는 foundation model로는 많이 부족한 감이 있죠.<br>\n",
    "\n",
    "위에서 살펴본 것처럼<br>\n",
    "단순한 Causal LM에 불과한 kogpt-2는 생성해 낼 문장의 품질을<br>\n",
    "디코딩 단계에서 인위적으로 조절해주는 방법 밖에 쓸 수 없습니다.<br>\n",
    "하지만 RLHF를 kogpt-2에 적용한다면<br>\n",
    "더 좋은 문장을 생성해내는 방법을 모델이 스스로 학습해낼 수 있으리라 기대해 볼 수 있습니다.<br>\n",
    "고도의 prompting은 어렵겠지만<br>\n",
    "현재 상태에서 특정 task에 fine-tuning했을 때보다는 성능이 한층 더 개선될 수 있지 않을까요?<br>\n",
    "\n",
    "kogpt-2에 RLHF를 적용하기기 위해선<br>\n",
    "새로운 데이터셋으로 일련의 재학습을 해줘야 합니다.<br>\n",
    "그럼 각 단계별 모델 구현에 앞서 우리가 사용할 데이터셋을 확인해보도록 하겠습니다.<br>\n",
    "\n",
    "먼저 SFT를 시도할 initial 모델에 쓸 데이터셋을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **데이터셋 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '불고기용 고기 한우에요?',\n",
       "  'completion': \"'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\",\n",
       "  'tokens': 193},\n",
       " {'prompt': '쓰던 앱이 유료로 전환됐어',\n",
       "  'completion': \"'어떤 앱인지 모르기 때문에 정확한 답변을 드리기 어렵습니다. 하지만, 일반적으로 유료 전환된 앱은 기존 무료 앱에서 추가적인 기능이나 서비스를 제공하는 경우가 많습니다. 이 경우, 유료 전환 이전 가격이 매우 저렴하거나 무료인 경우가 많으므로, 앱을 계속 사용하려면 추가적인 비용을 지불해야 할 수 있습니다. 하지만, 유료 전환 이후에는 기존 사용자 또는 새로운 사용자 모두가 추가 기능과 높은 품질의 서비스를 이용할 수 있게 됩니다. 따라서, 앱 개발자는 유료 모델로 전환함으로써 앱의 수익을 증가시키고 더 나은 서비스를 제공할 수 있습니다.\",\n",
       "  'tokens': 288},\n",
       " {'prompt': '여친이랑 다툼',\n",
       "  'completion': \"'저는 인공지능이기 때문에 여친과의 다툼에 대해서는 조언을 드릴 수는 없습니다. 하지만 다투게 되면 상대방의 말을 경청하는 태도와 서로의 감정을 존중하는 것이 중요합니다. 논리적이고 차분한 대화를 통해 문제를 해결해보세요. 그리고 서로를 이해하고 서로의 의견을 수용하는 것이 중요합니다.\",\n",
       "  'tokens': 153}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl' \n",
    "with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 RM에 사용할 데이터셋을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?',\n",
       "  'completion_0': 'Allow me to answer your question. I know that you are curious about me.',\n",
       "  'completion_1': '번디는 다양한 인터뷰자들과 뉴스홍보 담당자들과의 면담 때 밝혔다.',\n",
       "  'completion_2': '라이언에게 말했다.',\n",
       "  'ranking': [2, 1, 0]},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?',\n",
       "  'completion_0': '개포주공아파트는 다섯 단지로 이루어져 있습니다.',\n",
       "  'completion_1': '이날 목송에서 구글상위노',\n",
       "  'completion_2': '개포주공아파트는 총 27개 단지로 이루어져 있습니다.',\n",
       "  'ranking': [2, 0, 1]},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?',\n",
       "  'completion_0': 'The diameter of the Metallic domain is bigger than the Hyperonic domain.',\n",
       "  'completion_1': '이 질문은 조금 불분명합니다. 김영삼 대통령이 후보 시절에 어떤 발언을 했고, 누가 그 발언을 문제삼았는지에 따라 답이 다를 수 있습니다.\\\\n\\\\n만약 김영삼 대통령이 후보 시절에 지역표심을 겨냥한 발언을 했다는 가정하에, 그 발언을 문제삼은 후보가 누구였는지를 대답하자면, 그 답은 이화선 당시 민주당 대통령 후보가 될 것입니다. 1992년 총선 때, 김영삼 대선후보는 \"집값이 오른 노량진역 부근의 부동산 가격은 세월호 폭침 후 \\\\\\'강남 도시재생\\\\\\' 일환으로 상승했다\"는 발언을 했습니다. 하지만 이화선 후보는 이 발언을 \"전국적으로 경제적 발전이 이루어지지 않은 지방민의 마음을 멀리해지려는 무례한 발언\"이라고 비판하며 문제삼았습니다.\\\\n\\\\n하지만, 이 질문을 답변하는 데 있어서 보다 명확한 정보가 있으면 답변을 보완할 수 있습니다.',\n",
       "  'completion_2': '김영삼의 후보 시절에 지역표심을 겨냥한 발언은 대통령 당선 전까지 대한민국 정부가 추구하고 있는 민주주의 광범위하게 확립과 보수의 사상을 이어가는 데 있어 지역경제 발전과 공공서비스 신속 개선을 위해 합리적인 국가 정책에 따르는 방향성을 제시하고 있습니다.',\n",
       "  'ranking': [1, 2, 0]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_2_RM = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl'\n",
    "with open(data_path_2_RM, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 PPO 학습에 쓰일 데이터를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'prompt': '번디는 자신이 탐정잡지, 범죄소설 그리고 성범죄 관련 실제 범죄 다큐멘터리들을 탐독했다고 누구에게 말했나?'},\n",
       " {'prompt': '개포주공아파트는 몇 단지로 이루어져 있나?'},\n",
       " {'prompt': '김영삼의 후보 시절 지역표심을 겨냥한 발언을 문제삼은 후보는?'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path_3_PPO = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl'\n",
    "with open(data_path_3_PPO, \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "print(len(list_data_dict))\n",
    "list_data_dict[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-3. Supervised Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SFT**\n",
    "\n",
    "이번 스텝에서는 kogpt-2를 instruction dataset으로 SFT를 진행해 보겠습니다.<br>\n",
    "\n",
    "먼저 필요한 라이브러리들을 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "import json\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 모델과 토크나이저를 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 인퍼런스 단계에서 사용할 prompt 딕셔너리 템플릿과 SFT 데이터셋 클래스를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Sequence\n",
    "\n",
    "class SFT_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
    "        super(SFT_dataset, self).__init__()\n",
    "        logging.warning(\"Loading data...\")\n",
    "\n",
    "        pattern_instruction = 'prompt'  # instruction\n",
    "        pattern_output = 'completion'  # response\n",
    "\n",
    "        data_path_1_SFT = '/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl'\n",
    "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
    "            list_data_dict = json.load(json_file)\n",
    "\n",
    "        PROMPT_DICT = {\n",
    "            \"prompt_input\": (\n",
    "                \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "            )\n",
    "        }\n",
    "\n",
    "        prompt_input = PROMPT_DICT[\"prompt_input\"]\n",
    "\n",
    "        sources = []\n",
    "        for example in list_data_dict:\n",
    "            tmp = prompt_input.format_map(example)\n",
    "            sources.append(tmp)\n",
    "\n",
    "        targets = []\n",
    "        for example in list_data_dict:\n",
    "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
    "        examples = [s + t for s, t in zip(sources, targets)]\n",
    "\n",
    "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source\n",
    "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
    "\n",
    "        input_ids = examples_tokenized[\"input_ids\"]\n",
    "        labels = copy.deepcopy(input_ids)\n",
    "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
    "            label[:source_len] = -100\n",
    "\n",
    "        data_dict = dict(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        self.input_ids = data_dict[\"input_ids\"]\n",
    "        self.labels = data_dict[\"labels\"]\n",
    "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))\n",
    "\n",
    "\n",
    "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
    "        tokenized_list = [\n",
    "            tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"longest\",\n",
    "                max_length=tokenizer.model_max_length,\n",
    "                truncation=True,\n",
    "            )\n",
    "            for text in strings\n",
    "        ]\n",
    "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
    "        input_ids_lens = labels_lens = [\n",
    "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
    "        ]\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            input_ids_lens=input_ids_lens,\n",
    "            labels_lens=labels_lens,\n",
    "        )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
    "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고<br>\n",
    "- ** SFT_dataset 클래스의 이니셜라이저에서\n",
    "label[:source_len] = -100 코드의 -100이 의미하는 게 무엇인가요?\n",
    "해당 코드가 필요한 이유와 그 기능은 무엇인가요?**\n",
    "    - [CrossEntropy](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorForSupervisedDataset(object): \n",
    "\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
    "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value= -100)\n",
    "        return dict(\n",
    "            input_ids=input_ids,\n",
    "            labels=labels,\n",
    "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 SFT_dataset 클래스를 사용해 훈련셋을 만들고 data collator 인스턴스를 만들겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading data...\n",
      "WARNING:root:Loading data done!!: 12000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : tensor([  739,   378,   378,   378, 14659, 13394, 37091, 10651,   383, 25841,\n",
      "         8006, 14914,   375,  7673, 20479,  8091, 22311,  9036, 30902, 13675,\n",
      "          375,   378,   378,   378, 41951,   454,  9549, 20549,   383,  8142,\n",
      "         7192, 14914,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n",
      "output: tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,   382, 37767, 13753,  8263,  7166,   739,  8352,  7659,\n",
      "         9594, 25585, 13600,  8022,  9378, 11532,  9887, 11218,  9111, 16691,\n",
      "        10351, 10561,  9128, 20479,  8091,  9065,  9446,  9036, 28420, 26521,\n",
      "        10163, 26367,  6958,  9030,  9882, 12317, 25882,  9209, 37194, 10351,\n",
      "         9036, 12168, 10529, 15989,  9719, 15434, 10552, 11188, 13362,  9036,\n",
      "        15805, 11300, 11846,  9146, 16691,  9181,  7397, 15806, 13480, 11342,\n",
      "        17596,  9161, 19996,  9025, 25006, 18595,  9966, 12592, 10751, 11814,\n",
      "         8711,  9046, 12450,  9117,  7377, 12521,     1])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SFT_dataset(data_path_1_SFT='/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_1_SFT.jsonl', tokenizer=tokenizer)\n",
    "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)\n",
    "\n",
    "print('input : %s'%train_dataset.input_ids[0])\n",
    "print('output: %s'%train_dataset.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : ### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이며, 직접적으로 식품에 관한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기용 고기는 한우, 쇠고기, 돼지고기 등 다양한 종류의 고기를 사용합니다. 하지만 한우는 대표적인 고급 육류로 알려져 있기 때문에, 한우를 사용하는 경우도 많습니다. 알러지나 개별 건강 상태에 따라 다를 수 있으니 충분한 정보 수집 후에 선택해 주시기 바랍니다.\n",
      "output: \n"
     ]
    }
   ],
   "source": [
    "# 텐서를 텍스트로 디코딩하는 함수\n",
    "def decode_tensor_to_text(tokenizer, tensor):\n",
    "    # 텐서를 CPU로 이동하고, numpy 배열로 변환\n",
    "    tensor = tensor.cpu().numpy()\n",
    "\n",
    "    # 패딩 토큰과 -100을 제외한 토큰만 선택\n",
    "    tokens = []\n",
    "    for token in tensor:\n",
    "        if token == tokenizer.pad_token_id or token == -100:  # 패딩 토큰 또는 -100일 경우 루프 종료\n",
    "            break\n",
    "        tokens.append(token)\n",
    "\n",
    "    # 토큰을 텍스트로 디코딩\n",
    "    decoded_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    return decoded_text\n",
    "\n",
    "# input_ids와 labels 텐서를 디코딩하여 텍스트로 출력\n",
    "input_text = decode_tensor_to_text(tokenizer, train_dataset.input_ids[0])\n",
    "output_text = decode_tensor_to_text(tokenizer, train_dataset.labels[0])\n",
    "\n",
    "print('input :', input_text)\n",
    "print('output:', output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련을 위한 마지막 단계로 Training arguments를 사용해 trainer 클래스를 정의하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"aiffel/KoChatGPT/test\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=5,\n",
    "    prediction_loss_only=True,\n",
    "    fp16 = True\n",
    "    )\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고\n",
    "- [Huggingface Trainer() document](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFT 훈련을 진행해볼까요? (빠르게 학습해보기 위해 1epoch만 돌려보도록 하겠습니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 06:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.984100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.687200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_1_SFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss가 잘 줄어들었나요?<br>\n",
    "이제 문장 생성 능력을 확인하기 위해<br>\n",
    "빠르게 허깅페이스의 pipleline 클래스를 사용하여 generator를 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 어시스턴트이기 때문에 불고기용 고기의 종류와 양에 대한 정보를 가지고 있지 않습니다. 하지만 일반적으로 불고기는 쇠고기와 함께 먹는 음식 중 하나입니다. 따라서 불고기를 먹을 수 있는 종류는 다양합니다. 예를 들어, 닭가슴살 스테이크, 오므라이스 샐러드 등이 있습니다.\n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'리처드 닉슨은 42대 부통령직을 수행했습니다.作)作)은 \"리처드 닉슨\"이 41대 부통령을 수행한 년도를 가리키는 말입니다.作)는 \"리처드 닉슨\"이 40대 부통령을 맡았던 년도를 의미합니다.作은 \"리처드슨\"이 50대 부통령\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어?\n",
      "\n",
      "### Response(응답):'시카고 오 헤어 국제공항은 미국 캘리포니아주 샌프란시스코에 위치해 있습니다.子供共和國際空港)이라고 불립니다.子供公和国際空港이라는 뜻입니다.子供空和國際公港이라는 이름을 가진 항공사는 다음과 같습니다.\\n\\n1. 대한항공\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇으로써 미세먼지 정보를 알 수 없습니다. 미세먼지 예보를 확인해 보시는 것이 좋겠습니다.\\n\\n미세먼지 예보: 일반적으로 미세먼지는 주로 중국에서 발원하여 중국 전역으로 퍼져나가기 때문에 중국발 미세먼지가 유입될\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='/aiffel/KoChatGPT/output_1_SFT', tokenizer=tokenizer)\n",
    "\n",
    "generation_args = dict(   \n",
    "    num_beams=4,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=375, # \\n   \n",
    "    max_new_tokens=64,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = ['불고기용 고기 한우에요?',\n",
    "               '리처드 닉슨이 43대 부통령직을 수행한 년도는?',\n",
    "               '시카고 오헤어 국제공항은 어디에 있어?',\n",
    "               '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
    "\n",
    "list_result = generator(list_prompt, **generation_args)   \n",
    "for prompt, result in zip(list_prompt, list_result):\n",
    "    print()\n",
    "    print((result[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고\n",
    "- [HuggingFace Text Generation strategies](https://huggingface.co/docs/transformers/v4.28.1/en/generation_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SFT 모델의 성능은 어떤가요?<br>\n",
    "SFT 단계를 최적화하기 위해선 무엇보다도 instruction dataset의 품질과 initial모델의 언어모델링 성능이 중요합니다.<br>\n",
    "GPT를 새로 pretrain 하여 언어모델 성능을 도약시키는 일은 우리의 학습목표를 넘어서는 일이니<br>\n",
    "우선은 데이터셋 전처리를 더 수행하고 최상의 디코딩 전략이 적용된 generator를 설계한다면<br>\n",
    "더 나은 성능을 기대해 볼 수 있을 것입니다.<br>\n",
    "하지만 지금은 baseline을 빠르게 돌려보는 게 목적입니다.<br>\n",
    "이제 다음 단계인 reward modeling으로 넘어가 보도록 하겠습니다.<br>\n",
    "\n",
    "메모리 관리를 위해 캐시를 비우고 넘어가겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-4. Reward Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 스텝에서는 RLHF의 두번째 단계인 Reward model을 설계하고 학습해보겠습니다.\n",
    "필요한 라이브러리들을 불러와 볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **RM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import Optional\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from chatgpt.dataset import RewardDataset\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.trainer import RewardModelTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModel, AutoConfig\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "from transformers.models.gpt2.modeling_gpt2 import GPT2Model\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import된 라이브러리들을 보면 SFT단계에서 사용했던 것과는 다른 모듈들이 몇 개 눈에 띕니다.<br>\n",
    "우선 chatgpt 폴더 안에 있는 RM 관련 모듈들이 눈에 띄네요.<br>\n",
    "NaiveStrategy라는 모듈도 있습니다.<br>\n",
    "원본 깃헙 레포짓에는 multi GPU를 사용해서도 KoChatGPT를 실습해볼 수 있도록 하고 있지만<br>\n",
    "우리는 single GPU를 사용해야 하는 환경이므로 학습전략을 고정시켜놓기 위해 해당 모듈을 따로 import했습니다.<br>\n",
    "마지막엔 허깅페이스의 transformers에서 gpt2 모델 관련 모듈들도 사용하고 있네요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Reward model을 설계해 볼까요?<br>\n",
    "GPTRM_custom 이라는 이름으로 클래스를 선언하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTRM_custom(RewardModel):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: Optional[str] = None,\n",
    "                 config: Optional[GPT2Config] = None,\n",
    "                 checkpoint: bool = False,\n",
    "                 lora_rank: int = 0,\n",
    "                 lora_train_bias: str = 'none',\n",
    "                 tokenizer=None) -> None:\n",
    "        if pretrained is not None:\n",
    "            model = GPT2Model.from_pretrained(pretrained)\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "        elif config is not None:\n",
    "            model = GPT2Model(config)\n",
    "        else:\n",
    "            model = GPT2Model(GPT2Config())\n",
    "        if checkpoint:\n",
    "            model.gradient_checkpointing_enable()\n",
    "\n",
    "        value_head = nn.Linear(model.config.n_embd, 1)\n",
    "        super().__init__(model, value_head, lora_rank, lora_train_bias)\n",
    "\n",
    "        if pretrained is not None:\n",
    "            self.model = model\n",
    "            self.pretrained = pretrained\n",
    "\n",
    "\n",
    "    def save_pretrained(self, dir):\n",
    "        if self.pretrained is not None:\n",
    "            self.model.save_pretrained(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 클래스의 원본 코드는 [이 링크](https://github.com/hpcaitech/ColossalAI/blob/2e16f842a9e5b1fb54e7e41070e9d2bb5cd64d7c/applications/ChatGPT/chatgpt/nn/gpt_rm.py)에서 확인하실 수 있습니다.\n",
    "\n",
    "여기서 주의깊게 봐야할 부분은 이니셜라이저의 value_head = nn.Linear(model.config.n_embd, 1) 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 SFT에서와 마찬가지로 사용할 모델과 토크나이저를 불러오겠습니다.<br>\n",
    "with구문의 NaiveStrategy()는 chatgpt/trainer/strategies 폴더의 base 모듈에서 정의된\n",
    "Strategy클래스를 상속한 NaiveStrategy클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at skt/kogpt2-base-v2 were not used when initializing GPT2Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('skt/kogpt2-base-v2')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "    padding_side=\"right\",\n",
    "    model_max_length=512,\n",
    ")\n",
    "\n",
    "with NaiveStrategy().model_init_context():\n",
    "        model = GPTRM_custom(pretrained='skt/kogpt2-base-v2', lora_rank=0, tokenizer=tokenizer).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 RM을 훈련시킬 때 사용할 ranking dataset을 만들어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before data num: 10220\n",
      "after  data num: 30660\n",
      "data example: \n",
      "{'prompt': '애플은 리사를 어떻게 처리했어', 'chosen': '애플이 누구인지 명확히 알 수 없어서, 리사가 누구인지와 어떤 상황에서 처리되었는지에 대한 추가적인 정보가 필요합니다. 따라서, 보다 정확한 답변을 제공할 수 없습니다.', 'rejected': '애플은 리사를 위해 고객 서비스 부서에서 고객 다양한 컴퓨터 관련 문제에 대해 응답하는 데 필요한 모든 지원을 제공했습니다. 사용자가 하드웨어 문제를 경험할 때, 전문가들은 필요한 수리(수리, 추가 부품 제공, 소프트웨어 업그레이드 등)을 제공해 드릴 수 있습니다. 또한, 사용자가 사용 방법 문제나 기타 문제를 경험할 때, 대화 상대로 사용자를 지원할 수 있는 전문 고객 서비스 직원들이 사용자에게 상담하고 도움을 주는 데 도움이 될 수 있는 정보를 제공합니다. 또한, 인터넷에서 제공되는 정보를 통해 문제를 해결하거나 고객 서비스 웹 사이트를 통해 자신의 문제를 진단할 수 있도록 하는 등 다양한 방법으로 리사를 처리해 왔습니다.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_2_RM.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "\n",
    "total_data_ranking2chosen = []\n",
    "for tmp in list_data_dict:\n",
    "    one_data_ranking2chosen = []\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][1]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][0] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_0']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_0']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['prompt'] = tmp['prompt']\n",
    "    if tmp['ranking'][1] < tmp['ranking'][2]:\n",
    "        data['chosen'] = tmp['completion_1']\n",
    "        data['rejected'] = tmp['completion_2']\n",
    "    else:\n",
    "        data['chosen'] = tmp['completion_2']\n",
    "        data['rejected'] = tmp['completion_1']\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "print('before data num: %d'%(len(list_data_dict)))\n",
    "print('after  data num: %d'%(len(total_data_ranking2chosen)))\n",
    "print('data example: \\n%s'%total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kochatgpt_2_RM.jsonl 은<br>\n",
    "chatGPT, davinch, ada 세개 모델에 같은 prompt를 주고 얻은 세 답변을<br>\n",
    "순서대로 good, bad, worst로 간주해<br>\n",
    "순서를 뒤섞어 completion_0, completion_1, completion_2 세 키에 할당하여 만든 데이터셋입니다.<br>\n",
    "위와 같이 코드를 짜게 되면 chosen과 resjected에 각각<br>\n",
    "completion_0, completion_1, completion_2 세개 답변이 가능한 모든 조합으로 들어가게 되어<br>\n",
    "chosen에 worst 답변이 들어가고<br>\n",
    "rejected에 good답변이 들어간 데이터도 만들어집니다.<br>\n",
    "\n",
    "위와 같이 ranking dataset을 만들면 RM의 loss는 어떻게 계산이 되는 걸까요?<br>\n",
    "RM의 loss function은 pairwiseloss라는 이름으로 설계되어 있습니다.<br>\n",
    "아래 pairwiseloss 코드를 첨부했습니다.<br>\n",
    "원본 코드는 chatgpt/models 폴더의 loss.py 를 확인해보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class PairWiseLoss(nn.Module):\n",
    "\n",
    "    def forward(self, chosen_reward: torch.Tensor, reject_reward: torch.Tensor) -> torch.Tensor:\n",
    "        probs = torch.sigmoid(chosen_reward - reject_reward)\n",
    "        log_probs = torch.log(probs)\n",
    "        loss = -log_probs.mean()\n",
    "        return loss\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16. 위 코드블럭에서 probs = torch.sigmoid(chosen_reward - reject_reward) 코드를 찾아보세요.\n",
    "chosen_reward - reject_reward 식은 어떤 연산을 의미하나요?\n",
    "loss = -log_probs.mean() 코드는 무엇을 최대화하는 연산으로 해석할 수 있을까요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "total_data_ranking2chosen = []\n",
    "\n",
    "for tmp in list_data_dict:\n",
    "     prompt = tmp['prompt']\n",
    "     ranking = tmp['ranking']\n",
    "\n",
    "     for index in range(1, len(ranking)):\n",
    "         n = ranking[0]\n",
    "         m = ranking[index]\n",
    "\n",
    "\n",
    "         data = {\n",
    "             'prompt': prompt,\n",
    "             'chosen': tmp['completion_{}'.format(n)],\n",
    "             'rejected': tmp['completion_{}'.format(m)]\n",
    "         }\n",
    "\n",
    "         total_data_ranking2chosen.append(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17. 위 코드대로 ranking dataset 함수를 수정하게 되면 ranking data가 어떻게 만들어지게 되나요?\n",
    "둘의 차이를 비교하고 어떤 데이터셋을 사용하는게 더 적절한지 이야기해봅시다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 완성한 ranking dataset을 shuffle한 후 훈련셋을 만들어보겠습니다.<br>\n",
    "빠르게 돌려보기 위해 전체 데이터중 일부만 학습하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은?', 'chosen': '유아인이 류승완 감독을 만나 영화 베테랑의 시나리오를 받았던 곳은 류승완의 사무실입니다.', 'rejected': '대구 영화사옥'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(230319)\n",
    "random.shuffle(total_data_ranking2chosen)\n",
    "print(total_data_ranking2chosen[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1108.15it/s]\n",
      "100%|██████████| 200/200 [00:00<00:00, 859.21it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = total_data_ranking2chosen[:1000] \n",
    "eval_data = total_data_ranking2chosen[1000:1200]\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(eval_data))\n",
    "\n",
    "train_dataset = RewardDataset(train_data, tokenizer, 512)\n",
    "eval_dataset = RewardDataset(eval_data, tokenizer, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18. RewardDataset 클래스는 어떤 기능을 수행하나요?\n",
    "chatgpt/dataset폴더 내의 reward_dataset모듈을 참고해 답해보세요.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋이 잘 만들어졌는지 하나를 뽑아 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################\n",
      "## prompt ##\n",
      "흑고래의 무게는 어느 정도야\n",
      "######################################################################\n",
      "## chosen ##\n",
      "흑고래의 평균 몸무게는 약 25~40톤 정도이지만, 최대 몸무게는 50톤 이상에 이를 수 있습니다.\n",
      "######################################################################\n",
      "## rejected ##\n",
      "흑고래의 무게는 매우 다양하게 달라집니다. 약 200kg에서 10톤까지 달라질 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "print('#'*70)\n",
    "print('## prompt ##')\n",
    "print(train_data[idx]['prompt'])\n",
    "print('#'*70)\n",
    "print('## chosen ##')\n",
    "print(train_data[idx]['chosen'])\n",
    "print('#'*70)\n",
    "print('## rejected ##')\n",
    "print(train_data[idx]['rejected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 RM을 학습해 보겠습니다.<br>\n",
    "\n",
    "(SFT 훈련때와 마찬가지로 RM 훈련시 많은 자원이 소모됩니다.<br>\n",
    "모델 체크포인트를 활용할 수 있으니, 각각의 모델을 더 많은 데이터로 더 오래 훈련하고자 할 시,<br>\n",
    "커널을 초기화 한 후 재학습을 해보세요.<br>\n",
    "지금은 빠르게 학습해보기 위해 1epoch만 돌려보도록 하겠습니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RewardModelTrainer(model=model,\n",
    "                             strategy=NaiveStrategy(),\n",
    "                             optim=Adam(model.parameters(), lr=5e-5),\n",
    "                             train_dataset=train_dataset,\n",
    "                             eval_dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Train step of epoch 0:   0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:52,  1.07it/s]\u001b[A\n",
      "Train step of epoch 0:   0%|          | 1/250 [00:00<03:52,  1.07it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:40,  1.12it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 2/250 [00:01<03:40,  1.12it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:36,  1.14it/s, loss=0.751]\u001b[A\n",
      "Train step of epoch 0:   1%|          | 3/250 [00:02<03:36,  1.14it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.534]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 4/250 [00:03<03:33,  1.15it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.476]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 5/250 [00:04<03:31,  1.16it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:29,  1.16it/s, loss=0.448]\u001b[A\n",
      "Train step of epoch 0:   2%|▏         | 6/250 [00:05<03:29,  1.16it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:28,  1.16it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 7/250 [00:06<03:28,  1.16it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:28,  1.16it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:   3%|▎         | 8/250 [00:06<03:28,  1.16it/s, loss=1.44] \u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:27,  1.16it/s, loss=1.44]\u001b[A\n",
      "Train step of epoch 0:   4%|▎         | 9/250 [00:07<03:27,  1.16it/s, loss=0.419]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:26,  1.16it/s, loss=0.419]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 10/250 [00:08<03:26,  1.16it/s, loss=0.508]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:25,  1.16it/s, loss=0.508]\u001b[A\n",
      "Train step of epoch 0:   4%|▍         | 11/250 [00:09<03:25,  1.16it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:25,  1.16it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:   5%|▍         | 12/250 [00:10<03:25,  1.16it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:24,  1.16it/s, loss=0.399]\u001b[A\n",
      "Train step of epoch 0:   5%|▌         | 13/250 [00:11<03:24,  1.16it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:23,  1.16it/s, loss=0.153]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 14/250 [00:12<03:23,  1.16it/s, loss=1.1]  \u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:12<03:23,  1.15it/s, loss=1.1]\u001b[A\n",
      "Train step of epoch 0:   6%|▌         | 15/250 [00:13<03:23,  1.15it/s, loss=0.567]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=0.567]\u001b[A\n",
      "Train step of epoch 0:   6%|▋         | 16/250 [00:13<03:23,  1.15it/s, loss=1.34] \u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:22,  1.15it/s, loss=1.34]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 17/250 [00:14<03:22,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:21,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:   7%|▋         | 18/250 [00:15<03:21,  1.15it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 19/250 [00:16<03:21,  1.15it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 20/250 [00:17<03:20,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.625]\u001b[A\n",
      "Train step of epoch 0:   8%|▊         | 21/250 [00:18<03:19,  1.15it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 22/250 [00:19<03:18,  1.15it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:18,  1.15it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:   9%|▉         | 23/250 [00:19<03:18,  1.15it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:17,  1.14it/s, loss=0.798]\u001b[A\n",
      "Train step of epoch 0:  10%|▉         | 24/250 [00:20<03:17,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:16,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 25/250 [00:21<03:16,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:16,  1.14it/s, loss=0.623]\u001b[A\n",
      "Train step of epoch 0:  10%|█         | 26/250 [00:22<03:16,  1.14it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:15,  1.14it/s, loss=0.721]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 27/250 [00:23<03:15,  1.14it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:14,  1.14it/s, loss=0.615]\u001b[A\n",
      "Train step of epoch 0:  11%|█         | 28/250 [00:24<03:14,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:13,  1.14it/s, loss=0.576]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 29/250 [00:25<03:13,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:13,  1.14it/s, loss=0.482]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 30/250 [00:26<03:13,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:26<03:12,  1.14it/s, loss=0.578]\u001b[A\n",
      "Train step of epoch 0:  12%|█▏        | 31/250 [00:27<03:12,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:27<03:11,  1.14it/s, loss=0.467]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 32/250 [00:27<03:11,  1.14it/s, loss=0.865]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:28<03:11,  1.14it/s, loss=0.865]\u001b[A\n",
      "Train step of epoch 0:  13%|█▎        | 33/250 [00:28<03:11,  1.14it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:29<03:10,  1.13it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  14%|█▎        | 34/250 [00:29<03:10,  1.13it/s, loss=0.452]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:09,  1.13it/s, loss=0.452]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 35/250 [00:30<03:09,  1.13it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:09,  1.13it/s, loss=0.824]\u001b[A\n",
      "Train step of epoch 0:  14%|█▍        | 36/250 [00:31<03:09,  1.13it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:08,  1.13it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  15%|█▍        | 37/250 [00:32<03:08,  1.13it/s, loss=0.848]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:07,  1.13it/s, loss=0.848]\u001b[A\n",
      "Train step of epoch 0:  15%|█▌        | 38/250 [00:33<03:07,  1.13it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:07,  1.13it/s, loss=0.458]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 39/250 [00:34<03:07,  1.13it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:34<03:06,  1.13it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  16%|█▌        | 40/250 [00:34<03:06,  1.13it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:35<03:05,  1.12it/s, loss=0.395]\u001b[A\n",
      "Train step of epoch 0:  16%|█▋        | 41/250 [00:35<03:05,  1.12it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:05,  1.12it/s, loss=0.423]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 42/250 [00:36<03:05,  1.12it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:04,  1.12it/s, loss=0.646]\u001b[A\n",
      "Train step of epoch 0:  17%|█▋        | 43/250 [00:37<03:04,  1.12it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<03:03,  1.12it/s, loss=0.781]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 44/250 [00:38<03:03,  1.12it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<03:02,  1.12it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 45/250 [00:39<03:02,  1.12it/s, loss=0.61] \u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<03:01,  1.12it/s, loss=0.61]\u001b[A\n",
      "Train step of epoch 0:  18%|█▊        | 46/250 [00:40<03:01,  1.12it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<03:00,  1.12it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 47/250 [00:41<03:00,  1.12it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<03:00,  1.12it/s, loss=0.672]\u001b[A\n",
      "Train step of epoch 0:  19%|█▉        | 48/250 [00:42<03:00,  1.12it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:42<02:58,  1.12it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  20%|█▉        | 49/250 [00:43<02:58,  1.12it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:57,  1.12it/s, loss=0.612]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 50/250 [00:43<02:57,  1.12it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:56,  1.12it/s, loss=0.847]\u001b[A\n",
      "Train step of epoch 0:  20%|██        | 51/250 [00:44<02:56,  1.12it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:56,  1.12it/s, loss=0.457]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 52/250 [00:45<02:56,  1.12it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:55,  1.12it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  21%|██        | 53/250 [00:46<02:55,  1.12it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:54,  1.12it/s, loss=0.411]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 54/250 [00:47<02:54,  1.12it/s, loss=0.333]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:53,  1.13it/s, loss=0.333]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 55/250 [00:48<02:53,  1.13it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:51,  1.13it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  22%|██▏       | 56/250 [00:49<02:51,  1.13it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:50<02:51,  1.13it/s, loss=0.563]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 57/250 [00:50<02:51,  1.13it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:49,  1.13it/s, loss=0.539]\u001b[A\n",
      "Train step of epoch 0:  23%|██▎       | 58/250 [00:50<02:49,  1.13it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:49,  1.13it/s, loss=0.584]\u001b[A\n",
      "Train step of epoch 0:  24%|██▎       | 59/250 [00:51<02:49,  1.13it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:47,  1.13it/s, loss=0.652]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 60/250 [00:52<02:47,  1.13it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:46,  1.13it/s, loss=0.326]\u001b[A\n",
      "Train step of epoch 0:  24%|██▍       | 61/250 [00:53<02:46,  1.13it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:45,  1.13it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0:  25%|██▍       | 62/250 [00:54<02:45,  1.13it/s, loss=0.175]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:44,  1.13it/s, loss=0.175]\u001b[A\n",
      "Train step of epoch 0:  25%|██▌       | 63/250 [00:55<02:44,  1.13it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:43,  1.14it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 64/250 [00:56<02:43,  1.14it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:57<02:42,  1.14it/s, loss=0.346]\u001b[A\n",
      "Train step of epoch 0:  26%|██▌       | 65/250 [00:57<02:42,  1.14it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:58<02:41,  1.14it/s, loss=0.767]\u001b[A\n",
      "Train step of epoch 0:  26%|██▋       | 66/250 [00:58<02:41,  1.14it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:41,  1.13it/s, loss=0.188]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 67/250 [00:58<02:41,  1.13it/s, loss=0.861]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:40,  1.14it/s, loss=0.861]\u001b[A\n",
      "Train step of epoch 0:  27%|██▋       | 68/250 [00:59<02:40,  1.14it/s, loss=0.38] \u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:39,  1.14it/s, loss=0.38]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 69/250 [01:00<02:39,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:38,  1.14it/s, loss=0.791]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 70/250 [01:01<02:38,  1.14it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:37,  1.14it/s, loss=0.731]\u001b[A\n",
      "Train step of epoch 0:  28%|██▊       | 71/250 [01:02<02:37,  1.14it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:03<02:36,  1.14it/s, loss=0.528]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 72/250 [01:03<02:36,  1.14it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:04<02:35,  1.14it/s, loss=0.775]\u001b[A\n",
      "Train step of epoch 0:  29%|██▉       | 73/250 [01:04<02:35,  1.14it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:05<02:34,  1.14it/s, loss=0.714]\u001b[A\n",
      "Train step of epoch 0:  30%|██▉       | 74/250 [01:05<02:34,  1.14it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:05<02:33,  1.14it/s, loss=0.591]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 75/250 [01:05<02:33,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:32,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  30%|███       | 76/250 [01:06<02:32,  1.14it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:31,  1.14it/s, loss=0.723]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 77/250 [01:07<02:31,  1.14it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:30,  1.14it/s, loss=0.444]\u001b[A\n",
      "Train step of epoch 0:  31%|███       | 78/250 [01:08<02:30,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:29,  1.14it/s, loss=0.628]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 79/250 [01:09<02:29,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:10<02:28,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 80/250 [01:10<02:28,  1.14it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:11<02:27,  1.15it/s, loss=0.689]\u001b[A\n",
      "Train step of epoch 0:  32%|███▏      | 81/250 [01:11<02:27,  1.15it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:12<02:26,  1.15it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 82/250 [01:12<02:26,  1.15it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.833]\u001b[A\n",
      "Train step of epoch 0:  33%|███▎      | 83/250 [01:12<02:25,  1.15it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  34%|███▎      | 84/250 [01:13<02:24,  1.15it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:23,  1.15it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 85/250 [01:14<02:23,  1.15it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:22,  1.15it/s, loss=0.727]\u001b[A\n",
      "Train step of epoch 0:  34%|███▍      | 86/250 [01:15<02:22,  1.15it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:21,  1.15it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  35%|███▍      | 87/250 [01:16<02:21,  1.15it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:17<02:20,  1.15it/s, loss=0.465]\u001b[A\n",
      "Train step of epoch 0:  35%|███▌      | 88/250 [01:17<02:20,  1.15it/s, loss=0.919]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:18<02:20,  1.15it/s, loss=0.919]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 89/250 [01:18<02:20,  1.15it/s, loss=0.821]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:18<02:19,  1.15it/s, loss=0.821]\u001b[A\n",
      "Train step of epoch 0:  36%|███▌      | 90/250 [01:19<02:19,  1.15it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  36%|███▋      | 91/250 [01:19<02:18,  1.15it/s, loss=0.61] \u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.61]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 92/250 [01:20<02:17,  1.15it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.595]\u001b[A\n",
      "Train step of epoch 0:  37%|███▋      | 93/250 [01:21<02:16,  1.15it/s, loss=0.856]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:15,  1.15it/s, loss=0.856]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 94/250 [01:22<02:15,  1.15it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:23<02:14,  1.15it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 95/250 [01:23<02:14,  1.15it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:24<02:13,  1.15it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  38%|███▊      | 96/250 [01:24<02:13,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:25<02:13,  1.15it/s, loss=0.703]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 97/250 [01:25<02:13,  1.15it/s, loss=0.811]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.811]\u001b[A\n",
      "Train step of epoch 0:  39%|███▉      | 98/250 [01:25<02:12,  1.15it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  40%|███▉      | 99/250 [01:26<02:11,  1.15it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:10,  1.15it/s, loss=0.603]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 100/250 [01:27<02:10,  1.15it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:09,  1.15it/s, loss=0.657]\u001b[A\n",
      "Train step of epoch 0:  40%|████      | 101/250 [01:28<02:09,  1.15it/s, loss=0.7]  \u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:08,  1.15it/s, loss=0.7]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 102/250 [01:29<02:08,  1.15it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:30<02:07,  1.15it/s, loss=0.684]\u001b[A\n",
      "Train step of epoch 0:  41%|████      | 103/250 [01:30<02:07,  1.15it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:31<02:07,  1.15it/s, loss=0.734]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 104/250 [01:31<02:07,  1.15it/s, loss=0.765]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:32<02:06,  1.15it/s, loss=0.765]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 105/250 [01:32<02:06,  1.15it/s, loss=0.65] \u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:32<02:05,  1.15it/s, loss=0.65]\u001b[A\n",
      "Train step of epoch 0:  42%|████▏     | 106/250 [01:32<02:05,  1.15it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.682]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 107/250 [01:33<02:04,  1.15it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:03,  1.15it/s, loss=0.725]\u001b[A\n",
      "Train step of epoch 0:  43%|████▎     | 108/250 [01:34<02:03,  1.15it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:02,  1.15it/s, loss=0.606]\u001b[A\n",
      "Train step of epoch 0:  44%|████▎     | 109/250 [01:35<02:02,  1.15it/s, loss=0.66] \u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:01,  1.15it/s, loss=0.66]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 110/250 [01:36<02:01,  1.15it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:37<02:01,  1.15it/s, loss=0.757]\u001b[A\n",
      "Train step of epoch 0:  44%|████▍     | 111/250 [01:37<02:01,  1.15it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:38<02:00,  1.15it/s, loss=0.605]\u001b[A\n",
      "Train step of epoch 0:  45%|████▍     | 112/250 [01:38<02:00,  1.15it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:39<01:59,  1.15it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  45%|████▌     | 113/250 [01:39<01:59,  1.15it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:39<01:58,  1.14it/s, loss=0.656]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 114/250 [01:39<01:58,  1.14it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:40<01:57,  1.14it/s, loss=0.829]\u001b[A\n",
      "Train step of epoch 0:  46%|████▌     | 115/250 [01:40<01:57,  1.14it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.15it/s, loss=0.668]\u001b[A\n",
      "Train step of epoch 0:  46%|████▋     | 116/250 [01:41<01:57,  1.15it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.588]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 117/250 [01:42<01:56,  1.15it/s, loss=0.558]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.15it/s, loss=0.558]\u001b[A\n",
      "Train step of epoch 0:  47%|████▋     | 118/250 [01:43<01:55,  1.15it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:44<01:54,  1.14it/s, loss=0.502]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 119/250 [01:44<01:54,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:45<01:53,  1.14it/s, loss=0.522]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 120/250 [01:45<01:53,  1.14it/s, loss=0.997]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:45<01:52,  1.14it/s, loss=0.997]\u001b[A\n",
      "Train step of epoch 0:  48%|████▊     | 121/250 [01:46<01:52,  1.14it/s, loss=0.786]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:46<01:51,  1.14it/s, loss=0.786]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 122/250 [01:46<01:51,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:47<01:51,  1.14it/s, loss=0.662]\u001b[A\n",
      "Train step of epoch 0:  49%|████▉     | 123/250 [01:47<01:51,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:50,  1.14it/s, loss=0.549]\u001b[A\n",
      "Train step of epoch 0:  50%|████▉     | 124/250 [01:48<01:50,  1.14it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:49,  1.14it/s, loss=0.747]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 125/250 [01:49<01:49,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.14it/s, loss=0.663]\u001b[A\n",
      "Train step of epoch 0:  50%|█████     | 126/250 [01:50<01:48,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:51<01:47,  1.14it/s, loss=0.698]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 127/250 [01:51<01:47,  1.14it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:52<01:46,  1.14it/s, loss=0.568]\u001b[A\n",
      "Train step of epoch 0:  51%|█████     | 128/250 [01:52<01:46,  1.14it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:53<01:45,  1.14it/s, loss=0.627]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 129/250 [01:53<01:45,  1.14it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:53<01:45,  1.14it/s, loss=0.641]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 130/250 [01:53<01:45,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:54<01:44,  1.14it/s, loss=0.571]\u001b[A\n",
      "Train step of epoch 0:  52%|█████▏    | 131/250 [01:54<01:44,  1.14it/s, loss=0.909]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:55<01:43,  1.14it/s, loss=0.909]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 132/250 [01:55<01:43,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:42,  1.14it/s, loss=0.597]\u001b[A\n",
      "Train step of epoch 0:  53%|█████▎    | 133/250 [01:56<01:42,  1.14it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:41,  1.14it/s, loss=0.784]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▎    | 134/250 [01:57<01:41,  1.14it/s, loss=0.73] \u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:58<01:41,  1.14it/s, loss=0.73]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 135/250 [01:58<01:41,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:59<01:40,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  54%|█████▍    | 136/250 [01:59<01:40,  1.14it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:00<01:39,  1.14it/s, loss=0.679]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▍    | 137/250 [02:00<01:39,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:00<01:38,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  55%|█████▌    | 138/250 [02:00<01:38,  1.14it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:01<01:37,  1.14it/s, loss=0.653]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 139/250 [02:01<01:37,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:02<01:36,  1.14it/s, loss=0.525]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▌    | 140/250 [02:02<01:36,  1.14it/s, loss=0.494]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:35,  1.14it/s, loss=0.494]\u001b[A\n",
      "Train step of epoch 0:  56%|█████▋    | 141/250 [02:03<01:35,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:04<01:34,  1.14it/s, loss=0.622]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 142/250 [02:04<01:34,  1.14it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:05<01:34,  1.14it/s, loss=0.867]\u001b[A\n",
      "Train step of epoch 0:  57%|█████▋    | 143/250 [02:05<01:34,  1.14it/s, loss=0.551]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:06<01:33,  1.14it/s, loss=0.551]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 144/250 [02:06<01:33,  1.14it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:07<01:32,  1.14it/s, loss=0.513]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 145/250 [02:07<01:32,  1.14it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:07<01:31,  1.14it/s, loss=0.655]\u001b[A\n",
      "Train step of epoch 0:  58%|█████▊    | 146/250 [02:07<01:31,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:08<01:30,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 147/250 [02:08<01:30,  1.14it/s, loss=0.383]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:09<01:29,  1.14it/s, loss=0.383]\u001b[A\n",
      "Train step of epoch 0:  59%|█████▉    | 148/250 [02:09<01:29,  1.14it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:10<01:28,  1.14it/s, loss=0.614]\u001b[A\n",
      "Train step of epoch 0:  60%|█████▉    | 149/250 [02:10<01:28,  1.14it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:11<01:27,  1.14it/s, loss=0.667]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 150/250 [02:11<01:27,  1.14it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:12<01:27,  1.14it/s, loss=0.607]\u001b[A\n",
      "Train step of epoch 0:  60%|██████    | 151/250 [02:12<01:27,  1.14it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:13<01:26,  1.14it/s, loss=0.222]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 152/250 [02:13<01:26,  1.14it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:14<01:25,  1.14it/s, loss=0.517]\u001b[A\n",
      "Train step of epoch 0:  61%|██████    | 153/250 [02:14<01:25,  1.14it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:14<01:24,  1.14it/s, loss=0.596]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 154/250 [02:15<01:24,  1.14it/s, loss=1.11] \u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:15<01:23,  1.14it/s, loss=1.11]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 155/250 [02:15<01:23,  1.14it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:16<01:22,  1.14it/s, loss=1.16]\u001b[A\n",
      "Train step of epoch 0:  62%|██████▏   | 156/250 [02:16<01:22,  1.14it/s, loss=0.415]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:17<01:21,  1.14it/s, loss=0.415]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 157/250 [02:17<01:21,  1.14it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:18<01:20,  1.14it/s, loss=0.483]\u001b[A\n",
      "Train step of epoch 0:  63%|██████▎   | 158/250 [02:18<01:20,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:19<01:19,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▎   | 159/250 [02:19<01:19,  1.14it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:20<01:18,  1.14it/s, loss=0.762]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 160/250 [02:20<01:18,  1.14it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:21<01:18,  1.14it/s, loss=0.426]\u001b[A\n",
      "Train step of epoch 0:  64%|██████▍   | 161/250 [02:21<01:18,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:22<01:17,  1.14it/s, loss=0.669]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▍   | 162/250 [02:22<01:17,  1.14it/s, loss=0.5]  \u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:22<01:16,  1.14it/s, loss=0.5]\u001b[A\n",
      "Train step of epoch 0:  65%|██████▌   | 163/250 [02:22<01:16,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:23<01:15,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 164/250 [02:23<01:15,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:24<01:14,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▌   | 165/250 [02:24<01:14,  1.14it/s, loss=0.971]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:25<01:13,  1.14it/s, loss=0.971]\u001b[A\n",
      "Train step of epoch 0:  66%|██████▋   | 166/250 [02:25<01:13,  1.14it/s, loss=0.353]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:26<01:12,  1.14it/s, loss=0.353]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 167/250 [02:26<01:12,  1.14it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:27<01:11,  1.14it/s, loss=0.431]\u001b[A\n",
      "Train step of epoch 0:  67%|██████▋   | 168/250 [02:27<01:11,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:28<01:11,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 169/250 [02:28<01:11,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:29<01:10,  1.14it/s, loss=0.437]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 170/250 [02:29<01:10,  1.14it/s, loss=0.896]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:29<01:09,  1.14it/s, loss=0.896]\u001b[A\n",
      "Train step of epoch 0:  68%|██████▊   | 171/250 [02:29<01:09,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:30<01:08,  1.14it/s, loss=0.642]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 172/250 [02:30<01:08,  1.14it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:31<01:07,  1.14it/s, loss=0.818]\u001b[A\n",
      "Train step of epoch 0:  69%|██████▉   | 173/250 [02:31<01:07,  1.14it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:32<01:06,  1.14it/s, loss=0.434]\u001b[A\n",
      "Train step of epoch 0:  70%|██████▉   | 174/250 [02:32<01:06,  1.14it/s, loss=0.412]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:33<01:05,  1.14it/s, loss=0.412]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 175/250 [02:33<01:05,  1.14it/s, loss=0.62] \u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:34<01:04,  1.14it/s, loss=0.62]\u001b[A\n",
      "Train step of epoch 0:  70%|███████   | 176/250 [02:34<01:04,  1.14it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:35<01:03,  1.14it/s, loss=0.453]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 177/250 [02:35<01:03,  1.14it/s, loss=0.365]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:36<01:03,  1.14it/s, loss=0.365]\u001b[A\n",
      "Train step of epoch 0:  71%|███████   | 178/250 [02:36<01:03,  1.14it/s, loss=0.371]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:36<01:02,  1.14it/s, loss=0.371]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 179/250 [02:36<01:02,  1.14it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:37<01:01,  1.14it/s, loss=0.545]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 180/250 [02:37<01:01,  1.14it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:38<01:00,  1.14it/s, loss=0.707]\u001b[A\n",
      "Train step of epoch 0:  72%|███████▏  | 181/250 [02:38<01:00,  1.14it/s, loss=0.268]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:39<00:59,  1.14it/s, loss=0.268]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 182/250 [02:39<00:59,  1.14it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:40<00:58,  1.14it/s, loss=0.987]\u001b[A\n",
      "Train step of epoch 0:  73%|███████▎  | 183/250 [02:40<00:58,  1.14it/s, loss=1.14] \u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:41<00:57,  1.14it/s, loss=1.14]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▎  | 184/250 [02:41<00:57,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:42<00:56,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 185/250 [02:42<00:56,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:43<00:55,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  74%|███████▍  | 186/250 [02:43<00:55,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:43<00:55,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▍  | 187/250 [02:43<00:55,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:44<00:54,  1.14it/s, loss=0.378]\u001b[A\n",
      "Train step of epoch 0:  75%|███████▌  | 188/250 [02:44<00:54,  1.14it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:45<00:53,  1.14it/s, loss=0.648]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 189/250 [02:45<00:53,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:46<00:52,  1.14it/s, loss=0.869]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▌  | 190/250 [02:46<00:52,  1.14it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:47<00:51,  1.14it/s, loss=0.398]\u001b[A\n",
      "Train step of epoch 0:  76%|███████▋  | 191/250 [02:47<00:51,  1.14it/s, loss=0.28] \u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:48<00:50,  1.14it/s, loss=0.28]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 192/250 [02:48<00:50,  1.14it/s, loss=0.469]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:49<00:49,  1.14it/s, loss=0.469]\u001b[A\n",
      "Train step of epoch 0:  77%|███████▋  | 193/250 [02:49<00:49,  1.14it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:50<00:48,  1.14it/s, loss=0.858]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 194/250 [02:50<00:48,  1.14it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:50<00:48,  1.15it/s, loss=0.694]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 195/250 [02:50<00:48,  1.15it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:51<00:47,  1.14it/s, loss=0.443]\u001b[A\n",
      "Train step of epoch 0:  78%|███████▊  | 196/250 [02:51<00:47,  1.14it/s, loss=1.02] \u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:52<00:46,  1.14it/s, loss=1.02]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 197/250 [02:52<00:46,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:53<00:45,  1.14it/s, loss=0.675]\u001b[A\n",
      "Train step of epoch 0:  79%|███████▉  | 198/250 [02:53<00:45,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:54<00:44,  1.14it/s, loss=0.557]\u001b[A\n",
      "Train step of epoch 0:  80%|███████▉  | 199/250 [02:54<00:44,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:55<00:43,  1.14it/s, loss=0.559]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 200/250 [02:55<00:43,  1.14it/s, loss=0.47] \u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:56<00:42,  1.14it/s, loss=0.47]\u001b[A\n",
      "Train step of epoch 0:  80%|████████  | 201/250 [02:56<00:42,  1.14it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:57<00:42,  1.14it/s, loss=0.486]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 202/250 [02:57<00:42,  1.14it/s, loss=0.771]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:57<00:41,  1.14it/s, loss=0.771]\u001b[A\n",
      "Train step of epoch 0:  81%|████████  | 203/250 [02:57<00:41,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:58<00:40,  1.14it/s, loss=0.637]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 204/250 [02:58<00:40,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:59<00:39,  1.14it/s, loss=0.495]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 205/250 [02:59<00:39,  1.14it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:00<00:38,  1.14it/s, loss=0.562]\u001b[A\n",
      "Train step of epoch 0:  82%|████████▏ | 206/250 [03:00<00:38,  1.14it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:01<00:37,  1.14it/s, loss=0.772]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 207/250 [03:01<00:37,  1.14it/s, loss=0.55] \u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:02<00:36,  1.14it/s, loss=0.55]\u001b[A\n",
      "Train step of epoch 0:  83%|████████▎ | 208/250 [03:02<00:36,  1.14it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:03<00:35,  1.14it/s, loss=0.72]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▎ | 209/250 [03:03<00:35,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:04<00:35,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 210/250 [03:04<00:35,  1.14it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:04<00:34,  1.14it/s, loss=0.585]\u001b[A\n",
      "Train step of epoch 0:  84%|████████▍ | 211/250 [03:04<00:34,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:05<00:33,  1.14it/s, loss=0.408]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▍ | 212/250 [03:05<00:33,  1.14it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:06<00:32,  1.14it/s, loss=0.574]\u001b[A\n",
      "Train step of epoch 0:  85%|████████▌ | 213/250 [03:06<00:32,  1.14it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:07<00:31,  1.14it/s, loss=0.375]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 214/250 [03:07<00:31,  1.14it/s, loss=1.1]  \u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:08<00:30,  1.14it/s, loss=1.1]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▌ | 215/250 [03:08<00:30,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:09<00:29,  1.14it/s, loss=0.488]\u001b[A\n",
      "Train step of epoch 0:  86%|████████▋ | 216/250 [03:09<00:29,  1.14it/s, loss=0.853]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:10<00:28,  1.14it/s, loss=0.853]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 217/250 [03:10<00:28,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:11<00:28,  1.14it/s, loss=0.814]\u001b[A\n",
      "Train step of epoch 0:  87%|████████▋ | 218/250 [03:11<00:28,  1.14it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:11<00:27,  1.14it/s, loss=0.561]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 219/250 [03:11<00:27,  1.14it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:12<00:26,  1.14it/s, loss=0.392]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 220/250 [03:12<00:26,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:13<00:25,  1.14it/s, loss=0.621]\u001b[A\n",
      "Train step of epoch 0:  88%|████████▊ | 221/250 [03:13<00:25,  1.14it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:14<00:24,  1.14it/s, loss=0.626]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 222/250 [03:14<00:24,  1.14it/s, loss=0.331]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:15<00:23,  1.14it/s, loss=0.331]\u001b[A\n",
      "Train step of epoch 0:  89%|████████▉ | 223/250 [03:15<00:23,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:16<00:22,  1.14it/s, loss=0.756]\u001b[A\n",
      "Train step of epoch 0:  90%|████████▉ | 224/250 [03:16<00:22,  1.14it/s, loss=0.764]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:17<00:21,  1.14it/s, loss=0.764]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 225/250 [03:17<00:21,  1.14it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:18<00:21,  1.14it/s, loss=0.609]\u001b[A\n",
      "Train step of epoch 0:  90%|█████████ | 226/250 [03:18<00:21,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:18<00:20,  1.14it/s, loss=0.681]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 227/250 [03:18<00:20,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:19<00:19,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  91%|█████████ | 228/250 [03:19<00:19,  1.14it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:20<00:18,  1.14it/s, loss=0.492]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 229/250 [03:20<00:18,  1.14it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:21<00:17,  1.14it/s, loss=0.701]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 230/250 [03:21<00:17,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:22<00:16,  1.14it/s, loss=0.695]\u001b[A\n",
      "Train step of epoch 0:  92%|█████████▏| 231/250 [03:22<00:16,  1.14it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:23<00:15,  1.14it/s, loss=0.386]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 232/250 [03:23<00:15,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:24<00:14,  1.14it/s, loss=0.841]\u001b[A\n",
      "Train step of epoch 0:  93%|█████████▎| 233/250 [03:24<00:14,  1.14it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:25<00:14,  1.14it/s, loss=0.501]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▎| 234/250 [03:25<00:14,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:25<00:13,  1.14it/s, loss=0.573]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 235/250 [03:25<00:13,  1.14it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:26<00:12,  1.14it/s, loss=0.978]\u001b[A\n",
      "Train step of epoch 0:  94%|█████████▍| 236/250 [03:26<00:12,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:27<00:11,  1.14it/s, loss=0.484]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▍| 237/250 [03:27<00:11,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:28<00:10,  1.14it/s, loss=0.491]\u001b[A\n",
      "Train step of epoch 0:  95%|█████████▌| 238/250 [03:28<00:10,  1.14it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:29<00:09,  1.14it/s, loss=0.739]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 239/250 [03:29<00:09,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:30<00:08,  1.14it/s, loss=0.688]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▌| 240/250 [03:30<00:08,  1.14it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:31<00:07,  1.14it/s, loss=0.611]\u001b[A\n",
      "Train step of epoch 0:  96%|█████████▋| 241/250 [03:31<00:07,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:32<00:07,  1.14it/s, loss=0.485]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 242/250 [03:32<00:07,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:32<00:06,  1.14it/s, loss=0.878]\u001b[A\n",
      "Train step of epoch 0:  97%|█████████▋| 243/250 [03:32<00:06,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:33<00:05,  1.14it/s, loss=0.594]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 244/250 [03:33<00:05,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:34<00:04,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 245/250 [03:34<00:04,  1.14it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:35<00:03,  1.14it/s, loss=0.835]\u001b[A\n",
      "Train step of epoch 0:  98%|█████████▊| 246/250 [03:35<00:03,  1.14it/s, loss=0.76] \u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:36<00:02,  1.14it/s, loss=0.76]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 247/250 [03:36<00:02,  1.14it/s, loss=0.358]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:37<00:01,  1.14it/s, loss=0.358]\u001b[A\n",
      "Train step of epoch 0:  99%|█████████▉| 248/250 [03:37<00:01,  1.14it/s, loss=1.22] \u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:38<00:00,  1.14it/s, loss=1.22]\u001b[A\n",
      "Train step of epoch 0: 100%|█████████▉| 249/250 [03:38<00:00,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:39<00:00,  1.14it/s, loss=0.638]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:53<00:00, 233.45s/it]0,  1.14it/s, loss=0.446]\u001b[A\n",
      "Train step of epoch 0: 100%|██████████| 250/250 [03:53<00:00,  1.07it/s, loss=0.619, dist_mean=0.269]\u001b[A\n",
      "Train epoch: 100%|██████████| 1/1 [03:53<00:00, 233.45s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(use_lora=0)\n",
    "\n",
    "model.save_pretrained('aiffel/KoChatGPT/output_2_RM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RM 학습이 잘 되었는지 확인해보기 위해 임의의 문장을 입력한 후\n",
    "적절한 reward score를 출력하는지 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 똥멍청이 입니다\n",
      "reward score: -0.6\n"
     ]
    }
   ],
   "source": [
    "def inference_RM(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    output = model(input_ids)\n",
    "    output_reward = output.cpu().detach().numpy()[0]\n",
    "\n",
    "    print('input: %s\\nreward score: %.1f'%(input_text, output_reward))\n",
    "\n",
    "    return output_reward\n",
    "\n",
    "input_text = '인공지능은 똥멍청이 입니다'\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.\n",
      "reward score: -0.6\n"
     ]
    }
   ],
   "source": [
    "input_text = '인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다.'\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\n",
      "reward score: -0.4\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능(AI)은 컴퓨터에서 음성 및 작성된 언어를 보고 이해하고 번역하고 데이터를 분석하고 추천하는 기능을 포함하여 다양한 고급 기능을 수행할 수 있는 일련의 기술입니다. AI는 현대적인 컴퓨팅 혁신에서 중추적인 역할을 하며 개인과 비즈니스의 가치를 창출합니다. 예를 들어 광학 문자 인식(OCR)은 AI를 사용해 이미지 및 문서에서 텍스트 및 데이터를 추출하고, 구조화되지 않은 콘텐츠를 비즈니스에 바로 사용할 수 있게 만들고, 유용한 정보를 창출합니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\n",
      "reward score: -0.3\n"
     ]
    }
   ],
   "source": [
    "input_text = \"인공지능은 일반적으로 인간의 지능이 필요하거나 인간이 분석할 수 있는 것보다 규모가 큰 데이터를 포함하는 방식으로 추론, 학습 및 행동할 수 있는 컴퓨터 및 기계를 구축하는 것과 관련된 과학 분야입니다. AI는 컴퓨터 공학, 데이터 분석 및 통계, 하드웨어 및 소프트웨어 엔지니어링, 언어학, 신경 과학은 물론 철학과 심리학을 포함하여 여러 학문을 포괄하는 광범위한 분야입니다. 비즈니스의 운영 수준에서 AI는 주로 머신러닝과 딥 러닝을 기반으로 하는 기술 모음으로, 데이터 분석, 예상 및 예측, 객체 분류, 자연어 처리, 추천, 지능형 데이터 가져오기 등을 수행할 수 있습니다.\"\n",
    "\n",
    "output_reward = inference_RM(input_text=input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input text가 더 좋아질수록 reward score가 점진적으로 상승하나요?<br>\n",
    "각 reward score 값이 적절해 보이시나요?<br>\n",
    "reward score가 음수가 된다는 건 어떤 의미일까요?<br>\n",
    "그 전에 reward score가 음수도 될 수 있도록 하려면 어떻게 해야 할까요?<br>\n",
    "RM의 출력인 reward score가 scalar가 되도록 하는 게 왜 중요할까요?<br>\n",
    "\n",
    "RLHF의 마지막 단계인 PPO 학습을 통해 살펴보도록 하겠습니다.<br>\n",
    "\n",
    "여기서도 메모리 관리를 위해 한 번더 캐시를 비우고 넘어가겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-5. Proximal Policy Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PPO**\n",
    "\n",
    "드디어 RLHF의 마지막 세번째 단계인 PPO를 실습해볼 차례입니다.<br>\n",
    "사용할 라이브러리들을 불러오도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from chatgpt.models.base import RewardModel\n",
    "from chatgpt.models.gpt import GPTActor, GPTCritic\n",
    "from chatgpt.trainer import PPOTrainer\n",
    "from chatgpt.trainer.strategies import NaiveStrategy\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노드에서 소개하는 KoChatGPT의 경우<br>\n",
    "PPO에 사용할 actor모델은 1단계 SFT 모델을,<br>\n",
    "critic모델은 2단계 RM 모델을 사용합니다.<br>\n",
    "\n",
    "그리고 actor 모델이 critic 모델로부터 피드백을 받아 파라미터를 업데이트 할 때<br>\n",
    "적절한 페널티를 줄 수 있도록 하는 initial model은<br>\n",
    "SFT모델을 그대로 freezing 하여 사용합니다.<br>\n",
    "\n",
    "토크나이저는 pretrain 모델인 kogpt-2의 토크나이저를 그대로 사용해야겠죠?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KOGPT-2 model structure](../Images/lec_26/2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NaiveStrategy().model_init_context():\n",
    "    actor = GPTActor(pretrained='/aiffel/aiffel/KoChatGPT/output_1_SFT', lora_rank=0).to(torch.cuda.current_device())\n",
    "    critic = GPTCritic(pretrained='/aiffel/aiffel/KoChatGPT/output_2_RM', lora_rank=0).to(torch.cuda.current_device())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        'skt/kogpt2-base-v2', bos_token='</s>', eos_token='</s>', unk_token='</s>', pad_token='</s>',\n",
    "        padding_side=\"right\", \n",
    "        model_max_length=512\n",
    "    )\n",
    "\n",
    "    initial_model = deepcopy(actor)\n",
    "    reward_model = RewardModel(deepcopy(critic.model), deepcopy(critic.value_head)).to(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델학습에 사용할 옵티마이저와 모델을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_optim = Adam(actor.parameters(), lr=5e-6)\n",
    "critic_optim = Adam(critic.parameters(), lr=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(actor, actor_optim), (critic, critic_optim), reward_model, initial_model = NaiveStrategy().prepare(\n",
    "    (actor, actor_optim), (critic, critic_optim), reward_model, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO 학습에 쓸 데이터를 불러와 토크나이징 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/aiffel/KoChatGPT/data_kochatgpt/kochatgpt_3_PPO.jsonl', \"r\", encoding='utf-8-sig') as json_file:\n",
    "    list_data_dict = json.load(json_file)\n",
    "    list_prompt = [tmp['prompt'] for tmp in list_data_dict]\n",
    "\n",
    "def tokenize_fn(texts):\n",
    "    batch = tokenizer(texts, return_tensors='pt', max_length=96, padding=True, truncation=True)\n",
    "    return {k: v.cuda() for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[47311, 10448, 19008,  9792, 11780, 11308, 30190, 10929, 11849, 21663,\n",
      "         44389,  9574, 13799,   458, 14308, 12778, 22469, 20938, 44696,   458,\n",
      "         13799,   458, 14308, 12778, 11756, 18944,   389]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_fn('It takes something more than intelligence to act intelligently.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO는 별도의 PPOTrainer 클래스를 설계하여 학습시켜줘야 합니다.<br>\n",
    "빠르게 실습해보기 위해 1epoch만 돌려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PPOTrainer(NaiveStrategy(),\n",
    "                     actor,\n",
    "                     critic,\n",
    "                     reward_model,\n",
    "                     initial_model,\n",
    "                     actor_optim,\n",
    "                     critic_optim,\n",
    "                     max_epochs=1,  \n",
    "                     train_batch_size=8, \n",
    "                     tokenizer=tokenize_fn,\n",
    "                     max_length=128,\n",
    "                     do_sample=True,\n",
    "                     temperature=1.0,\n",
    "                     top_k=50,\n",
    "                     pad_token_id=tokenizer.pad_token_id,\n",
    "                     eos_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드블럭의 원본 코드는 chatgpt/trainer 폴더 내의 ppo.py 모듈에서 확인할 수 있습니다.<br>\n",
    "PPO는 SFT, RM 보다 훨씬 복잡한 단계로 설계되는 강화학습 알고리즘입니다.<br>\n",
    "PPO의 loss function은 chatgpt/models 폴더 내의 loss.py 모듈에서<br>\n",
    "PolicyLoss와 ValueLoss 클래스에 정의되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고\n",
    "- [Fine-tuning the LM with RL](https://gist.github.com/JoaoLages/c6f2dfd13d2484aa8bb0b2d567fbf093#3---fine-tuning-the-lm-with-rl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO에 대해 좀 더 자세히 알고 싶으신 분들은 허깅페이스에서 제공하는 [Deep RL Course](https://huggingface.co/learn/deep-rl-course/unit8/introduction?fw=pt)를 참고하세요.\n",
    "\n",
    "이제 PPO 학습을 진행하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode [1/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.72s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0, critic_loss=0.000441]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0, critic_loss=0.000441]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0, critic_loss=0.115]   \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.115]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.00648]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.92it/s, actor_loss=0, critic_loss=0.00648]\u001b[A\n",
      "Episode [1/10]: 100%|██████████| 3/3 [00:18<00:00,  6.22s/it]\n",
      "Episode [2/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.76s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.184, critic_loss=0.0236]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=0.184, critic_loss=0.0236]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=0.175, critic_loss=0.0648]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.175, critic_loss=0.0648]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.175, critic_loss=0.0537]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.175, critic_loss=0.0537]\u001b[A\n",
      "Episode [2/10]: 100%|██████████| 3/3 [00:18<00:00,  6.30s/it]\n",
      "Episode [3/10]:  67%|██████▋   | 2/3 [00:11<00:06,  6.01s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.126, critic_loss=0.0131]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=0.126, critic_loss=0.0131]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=0.127, critic_loss=0.000234]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.127, critic_loss=0.000234]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.83it/s, actor_loss=0.127, critic_loss=0.0143]  \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.84it/s, actor_loss=0.127, critic_loss=0.0143]\u001b[A\n",
      "Episode [3/10]: 100%|██████████| 3/3 [00:19<00:00,  6.57s/it]\n",
      "Episode [4/10]:  67%|██████▋   | 2/3 [00:12<00:06,  6.03s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.159, critic_loss=0.034]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.159, critic_loss=0.034]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.152, critic_loss=0.0308]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.152, critic_loss=0.0308]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.148, critic_loss=0.0136]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.148, critic_loss=0.0136]\u001b[A\n",
      "Episode [4/10]: 100%|██████████| 3/3 [00:19<00:00,  6.52s/it]\n",
      "Episode [5/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.78s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0476, critic_loss=0.00483]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.88it/s, actor_loss=-.0476, critic_loss=0.00483]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.88it/s, actor_loss=-.042, critic_loss=0.000531]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.042, critic_loss=0.000531]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=-.0495, critic_loss=0.0095] \u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=-.0495, critic_loss=0.0095]\u001b[A\n",
      "Episode [5/10]: 100%|██████████| 3/3 [00:19<00:00,  6.36s/it]\n",
      "Episode [6/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.81s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.146, critic_loss=0.0177]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=0.146, critic_loss=0.0177]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=0.156, critic_loss=0.0202]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.156, critic_loss=0.0202]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=0.147, critic_loss=0.0103]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.87it/s, actor_loss=0.147, critic_loss=0.0103]\u001b[A\n",
      "Episode [6/10]: 100%|██████████| 3/3 [00:19<00:00,  6.38s/it]\n",
      "Episode [7/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.84s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.03, critic_loss=0.00185]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.85it/s, actor_loss=0.03, critic_loss=0.00185]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.85it/s, actor_loss=0.0439, critic_loss=0.00114]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0439, critic_loss=0.00114]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=0.0493, critic_loss=0.00575]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=0.0493, critic_loss=0.00575]\u001b[A\n",
      "Episode [7/10]: 100%|██████████| 3/3 [00:19<00:00,  6.41s/it]\n",
      "Episode [8/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.85s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.088, critic_loss=0.0101]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s, actor_loss=-.088, critic_loss=0.0101]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.86it/s, actor_loss=-.0867, critic_loss=0.0115]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.0867, critic_loss=0.0115]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.86it/s, actor_loss=-.0973, critic_loss=0.0083]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0973, critic_loss=0.0083]\u001b[A\n",
      "Episode [8/10]: 100%|██████████| 3/3 [00:19<00:00,  6.40s/it]\n",
      "Episode [9/10]:  67%|██████▋   | 2/3 [00:10<00:05,  5.21s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=-.0169, critic_loss=0.000908]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.87it/s, actor_loss=-.0169, critic_loss=0.000908]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.87it/s, actor_loss=-.025, critic_loss=0.000363] \u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.025, critic_loss=0.000363]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.87it/s, actor_loss=-.0269, critic_loss=0.00269]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s, actor_loss=-.0269, critic_loss=0.00269]\u001b[A\n",
      "Episode [9/10]: 100%|██████████| 3/3 [00:18<00:00,  6.01s/it]\n",
      "Episode [10/10]:  67%|██████▋   | 2/3 [00:11<00:05,  5.83s/it]\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Train epoch [1/1]:   0%|          | 0/3 [00:00<?, ?it/s, actor_loss=0.0742, critic_loss=0.00596]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:00<00:01,  1.89it/s, actor_loss=0.0742, critic_loss=0.00596]\u001b[A\n",
      "Train epoch [1/1]:  33%|███▎      | 1/3 [00:01<00:01,  1.89it/s, actor_loss=0.0728, critic_loss=0.00408]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0728, critic_loss=0.00408]\u001b[A\n",
      "Train epoch [1/1]:  67%|██████▋   | 2/3 [00:01<00:00,  1.88it/s, actor_loss=0.0845, critic_loss=0.00444]\u001b[A\n",
      "Train epoch [1/1]: 100%|██████████| 3/3 [00:01<00:00,  1.88it/s, actor_loss=0.0845, critic_loss=0.00444]\u001b[A\n",
      "Episode [10/10]: 100%|██████████| 3/3 [00:17<00:00,  5.87s/it]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(list_prompt, \n",
    "            num_episodes=10,  \n",
    "            max_timesteps=3,\n",
    "            update_timesteps=3)\n",
    "\n",
    "model.save_pretrained('/aiffel/KoChatGPT/output_3_PPO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "드디어 SFT, RM 그리고 PPO 학습이 모두 완료되었습니다.<br>\n",
    "RLHF가 적용된 koGPT-2의 생성능력을 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Instruction(명령어):\n",
      "불고기용 고기 한우에요?\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 현재 판매되는 쇠고기의 등급과 양에 따라 다를 수 있습니다. 하지만 일반적으로 불고기용 쇠고기는 최상위 등급의 쇠고기이며, 등급이 높은 쇠고기도 최상위 등급으로 인정을 받습니다. 따라서, 등급이 높아지면 등급은 더 높은 가격으로 인정받게 되며, 현재 불고기용으로 판매되는 불고기용 쇠고기에 대한 등급이 높아지게 됩니다. 따라서, 실제 해당 쇠고기의 등급과 가격은 상이하지만, 현재 국내 기준으로는 불고기용으로 판매되는 불고기를 찾고자 한다면 해당 등급의 쇠고기의 등급이 높은 등급인 경우에는 불고기로 먹을 수 있는 고기로 먹으실 수 있습니다.子立さん らち ら ら らら\\  ら ら ら\\ ら  ラ ら ら ら  ら ら ら  ら ら \n",
      "\n",
      "### Instruction(명령어):\n",
      "리처드 닉슨이 43대 부통령직을 수행한 년도는?\n",
      "\n",
      "### Response(응답):'저는 데이터에 대한 의존도를 가지고 있지 않기 때문에 제임스 닉슨의 부통령직 수행년도에 대해 알지 못합니다. 정확한 정보와 관련해서는 \"리처드 닉슨의 47대 부통령직 수행년도를 알아내기 위한 추가적인 자료를 찾을 수 없습니다. 그러나 여러 국가들에서 활동하는 부통령은 여러 나라들에서 활동한 경험이 있을 가능성이 있습니다. 따라서 해당 국가들과의 대화와 상호협력 및 협력을 증진하기 위해 40대 부통령직의 수행년도에 대한 답변을 드리지 않습니다. '리처드 닉슨의 46대 부통령직 수행년도는 알려지지 않았습니다. '리처드 닉슨의 46대 부통령직 수행년도는 명확하지 않습니다. 다른 정보는 찾아볼 수 없습니다.' 죄송합니다. '리처드 닉슨의 43대 부통령직 수행년도는 리처드 닉슨이 39대 부통령직을 수행한 시기와 관련된 것일 가능성이 있습니다. '리처드 닉슨의 39대 부통령직 수행년도는 없습니다. '리처드 닉슨의 41대 부통령직 수행년도는 불분명합니다. '리처드 닉슨의 45대 부통령직 수행년도는 불분명합니다. '리처드 닉슨의 35대\n",
      "\n",
      "### Instruction(명령어):\n",
      "시카고 오헤어 국제공항은 어디에 있어\n",
      "\n",
      "### Response(응답):'저는 인공지능 챗봇이므로 시카고에 있는 국제공항에 관한 정보를 확인할 수 없습니다. 해당 지역의 항공사에 대한 확인은 가능합니다. 챗봇) http://www.iclue.com/home/home/home/home/home/eam/home/Home/home/Home/home/Home/home/Ihability/home/home/eam/Waiker/Home/analienceding/n\\n'push illed ush?\\n\\n\\n또한, 호텔의 예약 시스템을 제공해주시려면 해당 숙소의 예약 시스템을 제공하고 있습니다. 이 시스템에는 예약 가능한 호텔의 이름을 입력하면 됩니다. https://www. colove/push ituation/home/colviae/push/n\\n따라서, 해당 호텔에 대한 정보를 얻기 위해서는 호텔에 관한 정보를 제공해주시거나, 해당 호텔에 문의하시면\n",
      "\n",
      "### Instruction(명령어):\n",
      "오늘 미세먼지 어때?\n",
      "\n",
      "### Response(응답):'미세먼지 때문에 걱정된다면 대중교통, 대형마트, 음식점, 병원 등의 공공부문 공공요소에 대해 크게 걱정하지 않아도 됩니다. 공공요소에서 발생하는 오염물질이나 오염물질이 환경이나 건강을 위협할 수 있으므로, 가능한 모든 분야에서 철저히 관리하고 대비해야 합니다. 이러한 이유로 대중교통에서는 미세먼지나 초미세먼지 등의 오염물질을 줄이기 위해 차량, 대기전력 등의 차량관리시스템이 운영되고 있습니다. 이러한 환경 오염물질을 줄이려고 적극적으로 노력하며, 대기오염 감축을 위한 노력이 중요합니다. 또한, 공공장소에서 발생하는 미세먼지나 초미세먼지 등으로 인한 오염물질이 환경호르몬의 역할을 방해하거나 질병을 유발할 수 있으므로 철저히 관리하는 것이 가장 중요합니다. 太陽) 以後製人間 政法使, 以後製人間 政國, 以後製人間 正局 正局 政國 軍官 등의 다양한 공공요소에 대해서는 다양한 관리체계가 필요하다고 합니다. 宗神國、吏官, 以後製人間 正國, 以後製人間 政國, 以後製\n"
     ]
    }
   ],
   "source": [
    "def generation(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(\n",
    "        torch.cuda.current_device())\n",
    "    outputs = actor.generate(input_ids,\n",
    "                             max_length=250,\n",
    "                             do_sample=True,\n",
    "                             top_k=50,\n",
    "                             top_p=0.95,\n",
    "                             num_return_sequences=1)\n",
    "    output = tokenizer.batch_decode(outputs[0], skip_special_tokens=True)[0]\n",
    "    print()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "\n",
    "list_prompt = [\n",
    "    '불고기용 고기 한우에요?', \n",
    "    '리처드 닉슨이 43대 부통령직을 수행한 년도는?', \n",
    "    '시카고 오헤어 국제공항은 어디에 있어',\n",
    "    '오늘 미세먼지 어때?']\n",
    "\n",
    "list_prompt = [PROMPT_DICT['prompt_input'].format_map({'prompt': tmp}) for tmp in list_prompt]\n",
    "\n",
    "for input_text in list_prompt:\n",
    "    output = generation(input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-6. 마무리하며**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종 모델 학습 결과는 어떠셨나요?<br>\n",
    "중복 토큰 생성 문제를 비롯해 맥락에서 벗어난 한문이나 영문이 출력되기도 합니다.<br>\n",
    "kogpt-2에 SFT만 적용했을 때와 비교해보면 큰 차이를 느끼지 못할 수도 있습니다.<br>\n",
    "각 단계에서 사용되는 데이터셋을 충분히 정제하고, 훈련 사이클을 늘려 정교하게 디코딩한다면<br>\n",
    "훨씬 나은 성능을 기대해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLHF의 진가는 고도로 정제된 instruction dataset와 정교하게 설계된 보상체계로 학습되는 Reward model,<br>\n",
    "그리고 PPO 학습이 안정적으로 이뤄질 수 있도록 하는 충분한 크기의 foundation model이 뒷받침 되었을 때 발휘될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그러나 진짜 인간의 피드백이 반영된 데이터셋을 구축하기란 아주 어려운 일입니다.<br>\n",
    "첫 단계부터 큰 난관이라 할 수 있죠.<br>\n",
    "하지만 SFT만으로도 굉장히 훌륭한 언어모델을 만들 수 있습니다.<br>\n",
    "이준범님이 공개한[koalpaca](https://github.com/Beomi/KoAlpaca) 모델이 대표적인 사례라 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q20. koalpaca는 foundation model로 어떤 모델들을 사용했나요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q21. koalpaca의 레퍼런스 모델인 stanford alpaca가 사용한 모델과 데이터셋 그리고 학습방법은 무엇인가요?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고링크 - https://crfm.stanford.edu/2023/03/13/alpaca.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "충분한 컴퓨팅 파워가 마련된 여건이라면 koalpaca모델로 RLHF까지 진행해 볼 수도 있을 것 같습니다.<br>\n",
    "\n",
    "그 전에 오늘 노드를 기반으로 도전해 볼만한 과제들을 수행해보는 것이 도움이 될 것 같습니다.<br>\n",
    "\n",
    "그럼 우리 함께 프로젝트 노드로 이동해볼까요?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
