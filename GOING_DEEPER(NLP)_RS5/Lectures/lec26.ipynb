{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **26. LLM Trend Note 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-1. 들어가며**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안녕하세요 여러분:) LLM Trend Note2에 오신 걸 환영합니다!<br>\n",
    "\n",
    "지난 노드에서 우리는 최신 LLM의 흐름을 살펴보면서<br>\n",
    "Foundation model의 조건과 Emergent Abilities의 특징에 대해 알아보았습니다.<br>\n",
    "그기저엔 대규모 분산 컴퓨팅 기술과<br>\n",
    "보다 혁신적인 모델 아키텍쳐 및 학습기법에 대한 고민이<br>\n",
    "단단한 기초를 이루고 있다는 사실도 함께 말이죠.<br>\n",
    "\n",
    "이번 노드에서는 RLHF를 간접적으로 구현한 언어모델에 한국어 말뭉치를 학습시켜보도록 하겠습니다.<br>\n",
    "이른바 KoChatGPT라고 할 수 있겠죠?<br>\n",
    "KoChatGPT를 구현한 레퍼런스 코드는 고우영님의 깃헙에서 참고했습니다.<br>\n",
    "\n",
    "그러면 몇 가지 퀴즈를 풀어보면서 함께 워밍업을 해보도록 할까요?<br>\n",
    "(퀴즈 정답은 깃헙의 리드미를 꼼꼼히 읽어보시면 찾으실 수 있습니다:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **KoChatGPT 구현을 위해 사용한 foundation model**\n",
    "    - [참고 Git](https://github.com/SKT-AI/KoGPT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **KoChatGPT에서 차용한 Reward Model, Proximal Policy Optimization 알고리즘의 출처**\n",
    "    > CollosalAI\n",
    "    - [RLHF Training Stage2 - Training reward model :](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat#RLHF-training-stage2---training-reward-model)\n",
    "    - [RLHF Training Stage3 - Training model with reinforcement learning by human feedback :](https://github.com/hpcaitech/ColossalAI/tree/main/applications/Chat#RLHF-training-stage3---training-model-with-reinforcement-learning-by-human-feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 스텝부터 본격적으로 코드실습을 진행하기에 앞서<br>\n",
    "KoChatGPT를 영상으로 소개한 자료도 함께 살펴보도록 하겠습니다.<br>\n",
    "\n",
    "[Video (실전) ChatGPT - replica 만들기 코드실습](https://youtu.be/Iq8erq62s8c)<br>\n",
    "\n",
    "**소스코드에 대한 설명**은 40:57부터 1:12:40 구간을 참고하세요.<br>\n",
    "**SFT**와 **RM** 그리고 **RLHF에 대한 내용을 복습**하고 싶으신 분들은 12:18부터 28:53 구간을 참고하세요.<br>\n",
    "\n",
    "영상을 다 시청하셨다면,<br>\n",
    "오늘 노드의 학습목표와 학습내용을 짚어보고<br>\n",
    "프로젝트를 향해 힘차게 달려가볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습목표**\n",
    "\n",
    "1. ChatGPT 구현을 위해 필요한 데이터셋의 종류 및 특징을 설명할 수 있습니다.\n",
    "\n",
    "2. Initial Model, Reward Model, RLHF Model의 학습 로직을 설명할 수 있습니다.\n",
    "\n",
    "3. KoChatGPT를 개선해 나만의 ChatGPT를 구현할 수 있습니다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **학습내용**\n",
    "\n",
    "1. Supervised Fine Tuning\n",
    "\n",
    "2. Reward Model의 ranking algorithm 및 loss fuction 설계 원리\n",
    "\n",
    "3. 언어모델을 강화학습하기 위한 방법론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **준비물**\n",
    "\n",
    "LMS 클라우드 및 로컬 컴퓨터에서 진행할 경우 (우분투 20.04 기준) 아래와 같은 환경 및 라이브러리들이 요구됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Environment & Libraries**\n",
    "\n",
    "```shell\n",
    "#torch와 cuda 버전은 https://pytorch.kr/get-started/previous-versions/ 사이트를 참고해 \n",
    "#dependency를 맞춰 설치하시면 됩니다.\n",
    "wget https://developer.download.nvidia.com/compute/cuda/11.6.0/local_installers/cuda_11.6.0_510.39.01_linux.run\n",
    "sudo sh cuda_11.6.0_510.39.01_linux.run\n",
    "\n",
    "pip uninstall torch -y\n",
    "pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "\n",
    "pip install transformers==4.28.0\n",
    "pip install colossalai==0.2.7\n",
    "\n",
    "pip install openai\n",
    "pip install langchain==0.0.113\n",
    "pip install pandas>=1.4.1\n",
    "\n",
    "pip install --upgrade accelerate\n",
    "pip install bitsandbytes\n",
    "pip install loralib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 대부분은 컨테이너에 이미 설치가 되어 있지만<br>\n",
    "별도로 설치가 필요한 라이브러리가 있습니다.<br>\n",
    "\n",
    "**cloud shell에서 아래와 같이 KochatGPT를 설치해주세요. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "cd aiffel \n",
    "git clone https://github.com/airobotlab/KoChatGPT  \n",
    "cd KoChatGPT/colossalai_ChatGPT_230319/\n",
    "pip install .  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필수 requirement들이 잘 설치되어 있는지 확인해볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-2. Base model and Dataset for RLHF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-3. Supervised Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-4. Reward Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-5. Proximal Policy Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **26-6. 마무리하며**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
