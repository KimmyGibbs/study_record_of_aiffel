{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **25. LLM Trend Note 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-1. 들어가며**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "안녕하세요 여러분:) LLM Trend Note1 에 오신걸 환영합니다!\n",
    "<br><br>\n",
    "최신 트렌드라는 게 따라가자니 어디서부터 시작해야할지 막막하고,<br>\n",
    "보고 있자니 이 기술이 앞으로도 유효할지 모르겠고,<br>\n",
    "아마 이 노드에서도 시간을 들여 숙고해볼 만한 가치가 없는 내용이<br>\n",
    "여러분들께서 노드를 보시게 될 시점엔 많아지게 되는 건 아닐까<br>\n",
    "저 역시 한편으론 걱정이 되기도 합니다.<br>\n",
    "이 노드를 작성하기 위해 자료를 수집하는 동안에도 closed source가 open되기도 했고<br>\n",
    "이런 자료가 있었으면 좋겠다 싶은 것들이 다음 날에 짠 하고 공개되곤 했으니까요.<br>\n",
    "<br>\n",
    "하지만 다른 한편으로 트렌드란<br>\n",
    "오랜 시간의 압력으로 굳어져 크게 변할 수 없어 보이는 현상이나<br>\n",
    "현재까지 이룩한 문명의 힘으로 규정지어진 기술적, 사회적 사실들로부터 생겨나고 바뀌는 것이기도 하지요.<br>\n",
    "그래서 우리는 아래에 적은 몇가지 fact로부터 출발해보고자 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fact 1.**\n",
    "\n",
    "전 세계에서 사용되는 언어에 대한 각종 통계를 발표하는 [에스놀로그](https://www.ethnologue.com/)에 따르면\n",
    "2022년 기준 지구상엔 7168개의 언어가 있다고 합니다.\n",
    "그 중에서 한국어는 사용자 수 기준 20위권 안팎에 있다고 기록되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처: https://www.neuralspace.ai/challenges-in-using-nlp-for-low-resource-languages-and-how-neuralspace-solves-them](../Images/lec_25/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 2023년 3월 14일 OpenAI가 발표한 [GPT-4](https://openai.com/research/gpt-4)에 따르면,\n",
    "한국어는 아프리카에서 쓰는 스와힐리, 영국 웨일스 지방의 언어인 웰시와 함께 low resource language로 분류됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fact 2.**\n",
    "\n",
    "2022년 10월에 발표된<br>\n",
    "[Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning](https://arxiv.org/pdf/2211.04325.pdf)\n",
    "이라는 흥미로운 제목의 논문에 따르면, 전 세계의 디지털화 된 고품질 텍스트 데이터의 총 재고,\n",
    "다시 말해 전세계 NLP 개발자 및 연구자들이 모델 학습에 쓸 수 있는 사용 가능한 총 토큰 개수가\n",
    "4조 6000억에서 17조 2000억 개 사이로 추정된다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2211.04325.pdf](../Images/lec_25/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[또 다른 출처](https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications)에 의하면 그보다 훨씬 적은 약 3.2조개의 토큰으로 추산된다고도 하네요!\n",
    "<br><br>\n",
    "그런데 2023년 3월 현재 가장 핫한 OpenAI의 GPT-4와 더불어 주목받고 있는 Large Language Model(이하 LLM)인\n",
    "Meta의 LLaMA가 pre-train을 하는데 사용한 토큰의 개수는 자그마치 1.4T (1조 4천억) 개라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잠깐 정리해 볼까요?\n",
    "\n",
    "1. 전세계 7천여 개 언어 가운데 사용자 수로 치면 20등 정도 하는 한국어가,\n",
    "LLM 관점에선 그다지 풍부한 자원의 언어가 아니다.\n",
    "\n",
    "2. LLM을 학습하는 데 사용가능한 고품질 토큰이 수조 개 가량 있는데,\n",
    "최신 LLM은 해당 총 토큰 개수의 최대 1/4에 달하는 양을 학습하고 있다.\n",
    "\n",
    "안타깝게도 지금 이 글을 쓰는 시점에선 chatGPT의 LM으로 쓰인 GPT3.5 및 GPT-4가\n",
    "구체적으로 어떤 언어들을 몇개나 학습했는지 공개되지 않았습니다.\n",
    "대신 자료가 공개된 모델 중 참고해 볼만한 가장 최신 모델이 있습니다.\n",
    "<br><br>\n",
    "2022년 4월에 발표된 Google의 PaLM은 5천 400억 개 파라미터를 가진 현재 시점 기준 가장 큰 모델입니다.\n",
    "이 PaLM 이란 모델이 학습에 사용한 토큰 개수는 총 7천 800억개입니다.\n",
    "여기서 한국어 토큰은 약 0.2%를 차지합니다. [참고](https://arxiv.org/pdf/2204.02311.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://lifearchitect.ai/models/](../Images/lec_25/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **자, 여기서 우리는 어떤 생각을 이어나가 볼 수 있을까요?**\n",
    "\n",
    "최신 모델 아키텍쳐와 분산학습 기술이 발전함에 따라 LLM의 모델 사이즈는 앞으로 더욱더 커질 수 있습니다.<br>\n",
    "또는 훨씬 더 좋은 성능을 내면서도 모델 사이즈는 줄어드는 쪽으로도 발전할 수 있겠죠.<br>\n",
    "어느 쪽이든 디지털 토큰의 총량을 다 먹어치우는 날은 머지 않아 도래할 것입니다.<br>\n",
    "전 세계 인구 수와 증감률, 인터넷 유저 수와 보급률의 추이를 통해 예상할 수 있는 시나리오지요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대한민국의 출산율은 OECD 회원국 중 유일하게 1명대 아래입니다.<br>\n",
    "정확히는 2013년부터 2022년까지 10년간 출산율 최하위를 기록하고 있습니다.<br>\n",
    "(2007년, 2012년 두 해만 꼴찌에서 두 번째)<br>\n",
    "(출처 : https://www.pressian.com/pages/articles/2023022215021464370)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면, UN에 따르면 세계인구 수는 2022년 11월 기준 80억명을 돌파했고,\n",
    "향후 80년간 110억명 대에 이를 것으로 추산합니다.<br>\n",
    "(출처 : https://ko.wikipedia.org/wiki/%EC%84%B8%EA%B3%84_%EC%9D%B8%EA%B5%AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한편, 전 세계의 7,000여개 언어 중 보존을 위한 조치를 하지 않으면\n",
    "향후 100년 내에 당장 소멸 위기에 처한 언어가 1,500 여개에 달한다고 합니다.<br>\n",
    "(출처 : http://thescienceplus.com/news/newsview.php?ncode=1065613046395135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 저런 통계량들을 종합해보면, Language Modeling을 위한 학습 데이터를 구성할 때,<br>\n",
    "한국어를 위시한 low resource language의 경우 심각한 불균형을 유지할 것이라고 말할 수 있습니다.<br>\n",
    "더불어 현재 이후 발표될 최신 모델들은 이 불균형한 학습 데이터 비율 구조에서 크게 벗어나지 않은 상태로<br>\n",
    "학습 가능한 모든 토큰을 학습하게 될 것이라고도 말해볼 수 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼에도 불구하고, 2023년 3월 기준 chatGPT에게 low resource language인 한국어로 질문을 했을 때<br>\n",
    "아래와 같이 꽤 괜찮은 한국어 답변을 내놓는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chatgpt_example](../Images/lec_25/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이러한 현실이 한국어로 NLP를 연구하며 서비스하는 사람들에게 어떤 의미를 지니고,<br>\n",
    "어떤 도전을 요구하는지에 관해선 이 노드의 마무리에 함께 생각해보도록 하겠습니다.<br>\n",
    "<br>\n",
    "**저렇게 엄청난 크기의 모델 안에 어떤 능력들이 숨어 있는 걸까요?**<br>\n",
    "**그 능력들을 가능하게 하는 기술들은 무엇일까요?**<br>\n",
    "**반대로 반드시 저렇게 거대한 모델이어야만 좋은 성능을 발휘하는 걸까요?**<br>\n",
    "<br>\n",
    "오늘 이 시간 대표적인 최신 LLM 모델과 그 아키텍쳐 및 학습기법들을 살펴보면서\n",
    "위 질문들에 대한 힌트를 얻어볼 수 있게 되면 좋겠습니다.\n",
    "나아가 현재 어떤 흐름으로 NLP가 흘러왔고 흘러가게 될지 헤아려 볼 수 있는 시간이 되시길 바래봅니다.\n",
    "<br><br>\n",
    "그럼 정리해 볼까요?\n",
    "<br><br>\n",
    "아래 세 가지 학습목표와 학습내용에 있는 키워드들을 찬찬히 읽어보신 후,\n",
    "본격적으로 노드를 진행하기 앞서 노드를 보기 전 드는 생각과\n",
    "보고 난 후 들게 될 생각을 비교해보는 것도 의미가 있을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **학습목표**\n",
    "\n",
    "1. LLM의 등장배경과 그 의의를 설명할 수 있습니다.\n",
    "\n",
    "2. 최신 LLM 모델들의 성능에 영향을 미치는 핵심 기술들을 설명할 수 있습니다.\n",
    "\n",
    "3. 당면한 문제와 한계를 파악하고 전망할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **학습내용**\n",
    "\n",
    "- Foundation Model과 Emergent Abilities\n",
    "- PaLM, FLAN, ChatGPT, LLaMA 등 최신 LLM 모델의 특징\n",
    "- 최신 LLM 모델들의 주요 아키텍쳐 (Sparse Attention, RLHF)\n",
    "- LLM을 더욱 효율적으로 학습시키는데 필요한 기술들 (LoRA, LLM.int8())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고\n",
    "1. [국립국어원(모두의 말뭉치)](https://corpus.korean.go.kr/request/reausetMain.do?lang=ko)\n",
    "2. [AI Hub](https://aihub.or.kr/aihubdata/data/list.do?pageIndex=1&currMenu=115&topMenu=100&dataSetSn=&srchdataClCode=DATACL001&srchOrder=&SrchdataClCode=DATACL002&searchKeyword=&srchDataRealmCode=REALM002&srchDataTy=DATA003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-2. LLM의 Emergent Abilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Statistic LM, Neural LM, Pre-trained LM 그리고 LLM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Foundation Model**\n",
    "\n",
    "foundation model 이라는 개념에 대해 들어보셨나요?<br>\n",
    "통계적 언어모델, 신경망 언어모델을 거쳐 Transfomer 아키텍쳐 등장 이후,\n",
    "우리는 사전 훈련된 모델을 사용해 downstream task를 수행하는 패러다임을 지나가고 있습니다.<br>\n",
    "2022년에 발표된 논문 [On the Opportunities and Risks of Foundation Models](https://arxiv.org/pdf/2108.07258.pdf) 에서는\n",
    "지금까지 나온 모든 Pre-trained LM(이하 PLM)들을\n",
    "foundation model 이라는 개념으로 지칭하며 새로운 패러다임을 제시합니다.\n",
    "<br><br>\n",
    "논문의 저자들은 foundation model을 두 가지 특징으로 정의합니다.<br>\n",
    "하나는 emergence, 다른 하나는 homogenization 입니다.\n",
    "<br><br>\n",
    "논문에 따르면, 2019년 이전에 언어 모델을 사용한 self-supervised learning은\n",
    "본질적으로 NLP의 하위 영역이었으며 NLP의 다른 개발과 병행하여 진행되었습니다.<br>\n",
    "RNN(LSTM)을 활용한 언어모델링과 seq2seq 아키텍쳐, 그리고 트랜스포머는\n",
    "성능과 태스크상의 차이로 그 위계가 분류되긴 했었지만\n",
    "비교적 동등한 수준에서 NLP의 가지를 이루고 있었다는 뜻입니다.\n",
    "<br><br>\n",
    "2019년 이후 언어 모델을 사용한 self-supervised learning은\n",
    "BERT를 사용하는 것이 표준이 되면서 NLP의 기반이 되었습니다.<br>\n",
    "단일 모델이 이러한 광범위한 작업에 유용할 수 있다는 건 foundation model 패러다임의 시작을 의미합니다.<br>\n",
    "거의 모든 최첨단 NLP 모델은 이제 BERT, RoBERTa, BART, T5 등과 같은 몇 가지 기본 모델 중 하나에서 채택됩니다.<br>\n",
    "이것이 foundation model의 homogenization(균질화)가 의미하는 바입니다.\n",
    "<br><br>\n",
    "이러한 homogenization는 매우 높은 레버리지를 가집니다.<br>\n",
    "백본 모델로 쓰이는 몇가지 모델만 개선되면, NLP 전반에 즉각적으로 그 개선에 의한 이점이 퍼지게 되니까요.<br>\n",
    "반대로 모든 AI 시스템은 몇 가지 기본 모델의 동일한 문제(데이터의 편향 등)을 물려받을 수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2108.07258.pdf](../Images/lec_25/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 foundation model의 또 다른 특징인 emergence란 무엇일까요?<br>\n",
    "**우리는 이번 lecture 노드를 통해 emergence란 무엇인지,**<br>\n",
    "**그리고 emergence를 둘러싼 다양한 관점과**<br>\n",
    "**이를 뒷받침하는 최신 NLP 논문 및 모델들에 대해 살펴볼 것입니다.**\n",
    "<br><br>\n",
    "foundation model 패러다임은 머신러닝과 딥러닝에서 다루는 모든 종류의 model과 task를 망라합니다.<br>\n",
    "저희는 NLP를 보다 심도 있게 공부하기 위해 모였으니 LM에 집중해서 이야기를 해야겠죠?\n",
    "<br><br>\n",
    "그럼 Emergence로 가기 위한 첫 관문인 LM 그중에서도 LLM에 첫발을 내딛어 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **LLM**\n",
    "\n",
    "일반적으로 논문이나 깃헙에 공개된 레포짓에 나와 있는 모델 설명을 보면\n",
    "모델 이름 뒤에 small, base, large, XL 등 모델의 크기를 덧붙여 모델 이름을 지은 걸 볼 수가 있습니다.<br>\n",
    "BERT-Large, XLM-R Base, Flan-T5-XXL 와 같은 식으로 말이죠.<br>\n",
    "또 어떤 모델들은 m2m100_418M, GPT-NeoX-20B 처럼 구체적인 모델 파라미터 개수를 적기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://huggingface.co/blog/large-language-models](../Images/lec_25/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림은 지난 몇 년간 발표된 주요 모델들의 파라미터 스케일의 변화를 보여주는 그래프입니다.<br>\n",
    "Transfer learning의 효시라 부를 수 있는 ELMo에서 시작해 매 해마다 LM의 크기는 10배씩 증가했습니다.\n",
    "<br><br>\n",
    "\"크기\"란 상대적인 개념입니다.<br>\n",
    "2018년에 발표된 BERT의 large모델은 340M (3억 4천만) 개의 파라미터를 가지고 있습니다.<br>\n",
    "그 당시로선 같은 해 나온 ELMo와 비교한 다면 \"Large\" language model 이라 부르는 게 타당해보입니다.\n",
    "<br><br>\n",
    "2022년 기준 가장 큰 모델은 540B 개의 파라미터를 가진 Google의 PaLM 입니다.<br>\n",
    "(위 그래프에 top-right에 있는 Megatron-Turing NLG 530B는\n",
    "NVIDIA에서 발표한 모델로 PaLM에 조금 못 미치는 크기입니다.)<br>\n",
    "BERT는 PaLM에 비하면 더 이상 large model이라 부를 수 없을 것 같습니다.<br>\n",
    "단위가 million에서 billion으로 바뀌었으니까요.<br>\n",
    "따라서 앞으로 (trillion 단위의)더 큰 사이즈의 모델이 나온다고 했을 때, \"Large\"의 기준단위는 계속 바뀌어 나갈 것 입니다.\n",
    "<br><br>\n",
    "그러나 이제부터 **우리가 지칭할 Large Language Model (이하 LLM) 에서 Large의 의미는**<br>\n",
    "**'크기의 상대적인 개념'에 구속되지 않습니다.**<br>\n",
    "다시 말해, 크기의 절대적인 기준이 있습니다.<br>\n",
    "**수백억에서 수천억개의 파라미터를 가진 Pretrained Language Model (이하 PLM) 을 LLM 이라고 부릅니다.**<br>\n",
    "(물론 이 기준 또한 낮아질 수 있습니다. 아마 그러할 가능성이 매우 농후해보입니다.)\n",
    "<br><br>\n",
    "참고로 LLM은 Mixture-of-Expert (MoE) 기법의 사용유무에 따라\n",
    "dense transformer models 과 sparse mixture-of-expert (MoE) models로 구분할 수 있는데<br>\n",
    "후자는 전자보다 훈련/추론 계산 시 더 많은 모델 파라미터를 가집니다.<br>\n",
    "dense transformer models에는 Jurassic-1, gopher, Megatron-Turing NLG 530B, LaMDA 등이 있고,<br>\n",
    "sparse mixture-of-expert (MoE) models에는 Glam, switch transformers 등이 있습니다.<br>\n",
    "(switch transformer와 MoE에 대해서는 \"modern NLP의 흐름에 올라타보자\" 노드를 참고하세요)\n",
    "<br><br>\n",
    "그렇다면, 수백억 이상의 파라미터 스케일을 가진 PLM을 LLM으로 분류할 때,\n",
    "이러한 LLM과, 그보다 작은 사이즈의 LM 사이에는 어떤 차이점이 있는 것일까요?\n",
    "<br><br>\n",
    "조금 더 구체적으로 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Emergnet abilities를 위한 배경지식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **In-context learning 과 Emergent Abilities**\n",
    "\n",
    "일단 LLM으로 분류되는 파라미터 스케일 기준의 배경부터 살펴보겠습니다.<br>\n",
    "아래 그림은 2019년부터 2023년 초까지 발표된 모델 중 10B 이상의 파라미터를 가진 모델들만 추려놓은 그림입니다.<br>\n",
    "(이번 노드에 언급되는 대부분의 모델들은 이 그림에서 찾아보실 수 있습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2303.18223.pdf](../Images/lec_25/7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 중에서 우리가 눈여겨 볼 LLM은 2020년에 발표된 GPT-3 입니다.\n",
    "<br><br>\n",
    "GPT-3는 175B (1천 750억)개의 파라미터를 트랜스포머 디코더 기반 아키텍쳐에 집어 넣은 LLM 입니다.<br>\n",
    "흥미롭게도, **파라미터 수가 일정 수준을 초과한 LLM은 BERT와 같은 million 단위의 소규모 LM에 없는 성능을 나타냅니다.**<br>\n",
    "GPT-3를 개발한 OpenAI의 연구자들은 [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)논문에서<br>\n",
    "**“in-context learning”** 의 일종인 zero-shot, one-shot, few-shot 이라는 개념으로 이 성능을 정의했습니다.\n",
    "<br><br>\n",
    "그리고 2년 후 Google Research, Stanford University, UNC Chapel Hill, 그리고 DeepMind의 연구자들은\n",
    "이 성능이 어디서부터 기인하는 지를 가리켜 **Emergent Abilities** 라는 개념을 공론화하였습니다. [(참고)](https://arxiv.org/pdf/2206.07682.pdf)\n",
    "\n",
    "그렇습니다.\n",
    "바로 Emergent abilities가 수백억개를 초과하는 LLM이 가진 특징이자, 바꿔 말해 소규모 LM에서는 발견되지 않는 특징입니다.\n",
    "\n",
    "Emergent abilities 가 무엇인지 본격적으로 살펴보기 전에 먼저 그 배경이 되는 핵심 개념들을 슬쩍 엿보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.  Instruction Tuning 과 Chain-of-Thought Prompting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **instruction tuning**\n",
    "\n",
    "GPT-3 논문에서 소개하고 있는 zero-shot, one-shot, few-shot 은\n",
    "모델의 inference 단계에서 이뤄지는 작업입니다.<br>\n",
    "즉, gradient를 계산해 모델 파라미터 업데이트를 함으로써 학습하는 방법이 아니라는 뜻입니다.<br>\n",
    "zero-shot, one-shot, few-shot을 간단히 설명하면 아래와 같이 요약할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> zero-shot : 적절한 instruction이 담긴 지시문을 모델에 던져서 원하는 답변을 이끌어 내는 것입니다.<br>\n",
    "> one-shot, few-shot : 단순히 지시문만 주는 게 아니라 구체적인 예제를 던져서 원하는 답변을 이끌어 내는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM에 사용되는 위와 같은 추론 방법들은 후에 prompt learning 이라고도 불리게 됩니다.<br>\n",
    "적절한 instruction 내지 prompt를 주었을 때 더 모델로부터 더 나은 답변을 얻어 낼 수 있게 하는 것이지요.<br>\n",
    "GPT-3 논문에서 소개된 이 방법들은 이후 instruction tuning, prompt engineering 같은 방법론으로 발전하게 됩니다.\n",
    "<br><br>\n",
    "instruction tuning은 앞서 살펴본 그림에서 Google이 발표한 [FLAN](https://arxiv.org/pdf/2109.01652.pdf) 논문에 처음 등장합니다.\n",
    "<br><br>\n",
    "prompt engineering의 한 방법인 chain-of-thought prompting은 같은 그림에서 역시<br>\n",
    "Google이 발표한 [PaLM](https://arxiv.org/pdf/2204.02311.pdf) 논문에 자세한 설명이 실려 있습니다.\n",
    "<br><br>\n",
    "먼저 instruction tuning을 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **FLAN : Finetuned Language Models Are Zero-Shot Learners**\n",
    "\n",
    "FLAN 논문의 저자들은 zero-shot learning abilities를 개선하는 방법을 제안하는 것이 논문의 목적이라고 말합니다.<br>\n",
    "이를 위해 연구진들은 LaMDA (이하 람다) 모델을 사용했습니다.<br>\n",
    "람다는 GPT-3보다 좀 더 작은 137B 사이즈의 디코더 기반 트랜스포머 모델로 instruction tuning을 활용해<br>\n",
    "GPT-3보다 더 나은 성능의 zero-shot learning abilities를 달성했다고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2109.01652.pdf](../Images/lec_25/8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "람다에 대한 자세한 설명은 [LaMDA: Language Models for Dialog Applications](https://arxiv.org/pdf/2201.08239.pdf)논문을 참고하세요.\n",
    "<br><br>\n",
    "instruction tuning의 핵심은 다양한 종류의 NLP task를 instruction과<br>\n",
    "그에 상응하는 label로 이뤄진 pair dataset으로 fine-tuning한 후<br>\n",
    "한 번도 보지 못한 task에서 inference를 하여 만족할 만한 성능을 내는 튜닝방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2109.01652.pdf](../Images/lec_25/9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를 들어, commonsense reasoning task의 경우<br>\n",
    "위 그림에서처럼 instruction 지문에서 질문 내용에 참고가 될 목표를 지시해준 후<br>\n",
    "상식선에서 추론 가능한 답변을 target으로 주는 dataset을 모델에 fine-tuning 시킵니다.\n",
    "<br><br>\n",
    "더 정확히는, 먼저 아래 그림과 같이 기존에 공개된 데이터셋들을 총 12개 카테고리로 분류합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2109.01652.pdf](../Images/lec_25/10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그 다음, 각 데이터셋들을 instruction 형식으로 수정합니다.<br>\n",
    "구체적으로는 각 데이터셋 마다 10개의 instruction template을 만든 다음,<br>\n",
    "전체 데이터 셋에서 무작위로 template을 뽑아 fine-tuning을 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2109.01652.pdf](../Images/lec_25/11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 downstream task 별 fine-tuning 과 prompting 그리고 instruction tuning의 차이는 분명해보입니다.<br>\n",
    "일반적인 fine-tuning은 PLM을 특정 task 수행 능력에 특화시킵니다.<br>\n",
    "BART처럼 Pre-train 단계에서 여러 가지의 까다로운 pre-training objective 를 풀게 하여<br>\n",
    "서로 다른 복수의 downstream task에서 월등한 성능을 낸다하더라도<br>\n",
    "그 성능은 결국 풀고자 하는 특정 downstream task에 fine-tuning한 결과입니다.\n",
    "<br><br>\n",
    "prompting도 마찬가지입니다. GPT-3에서 제시한 few-shot은 결국<br>\n",
    "user가 의도적으로 prompting을 해야만 성능을 이끌어낼 수 있는 방법입니다.\n",
    "<br><br>\n",
    "instruction tuning은 서로 다른 종류의 downstream task를 instruction 형태의 데이터셋으로<br>\n",
    "한번에 fine-tuning하여<br>\n",
    "user가 prompt engineering을 할 필요 없이,<br>\n",
    "모델로 하여금 자연스럽게 user의 instruction에 따르는 답변을 내놓도록 하는 학습방법이라는 데 의의가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2109.01652.pdf](../Images/lec_25/12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정리하면, FLAN의 의의는 GPT-3보다 더 작은 모델을 fine-tuning 하여<br>\n",
    "모델에게 **instruction following** 능력을 직접적으로 부여했다는 데 있습니다.<br>\n",
    "더 중요한 건, fine-tuning 때 학습하지 않은 task에 대해서도<br>\n",
    "user의 instruction에 following하는 능력을 가지게 되었다는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instruction following은 뒤에서 살펴볼 emergent abilities 중 하나에 속합니다.<br>\n",
    "그렇다면 이 방법이 prompting보다 우월한 방법인 걸까요?\n",
    "<br><br>\n",
    "GPT-3는 앞서 말했듯이 175B이라는 어마어마한 크기의 모델입니다.<br>\n",
    "이런 LLM을 fine-tuning하는 건 비용과 효율면에서 좋은 시도라고 보기 어렵습니다.<br>\n",
    "FLAN 연구진이 instruction tuning을 하기 위해 사용한 LaMDA가 GPT-3보다 작은 모델이라곤 하지만<br>\n",
    "137B도 결코 작다고 할 수 없는 큰 사이즈의 LLM 입니다.\n",
    "<br><br>\n",
    "우리는 처음에 LLM이 소규모 LM에서 발견되지 않는 우수한 성능의 emergent abilities를 갖고 있다는 전제에서 출발했습니다.<br>\n",
    "이 말의 의미는 아주 많은 파라미터로 엄청난 양의 데이터를 단순히 auto-regressive 한 방법으로 학습시켰을 때\n",
    "모델이 어떤 의미에서는 인간이 명시적으로 가르쳐주지 않았음에도\n",
    "스스로 탁월한 언어이해(NLU)와 언어생성능력(NLG)을 가지게 되었다는 걸 뜻하는 것 같습니다.<br>\n",
    "마치 사람이 하는 것처럼 생각하는 방법을 터득한 것처럼 말이죠.\n",
    "<br><br>\n",
    "우리는 종종 \"의식의 흐름\" 대로 글을 썼다거나 말을 한다는 표현을 하곤 합니다.<br>\n",
    "chain of thought, 말 그대로 \"생각의 흐름\"과 같은 방식으로 prompting 했을 때,\n",
    "모델이 그 흐름 끝에 나올법한 답변을 내놓는 기술에 관한 이야기를 해보고자 합니다.<br>\n",
    "바로 chain-of-thought prompting 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Chain-of-Thought Prompting**\n",
    "\n",
    "앞서 살펴본 instruction tuning은 few-shot learning과 fine-tuning의 하이브리드라고 볼 수도 있습니다.<br>\n",
    "Google 연구진들은 \"chain-of-thought prompting\" 이라는 개념을 제안한 PaLM 논문에서<br>\n",
    "LLM의 규모를 극한으로 몰아붙였을 때, few-shot 능력이 얼마나 상승하게 될지를 실험했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PaLM](https://arxiv.org/pdf/2204.02311.pdf)논문에서\n",
    "연구진들은 무려 540B에 달하는 파라미터를 탑재한 디코더 기반 트랜스포머 모델을 사용했습니다.<br>\n",
    "더불어 소셜 미디어 대화, 필터링된 웹 페이지, 책, Github, 다국어 Wikipedia 및 뉴스에서 가져온<br>\n",
    "자그마치 780B 개의 토큰을 가지고 pre-train을 했습니다.<br>\n",
    "('자그마치'라고는 했지만 앞선 스텝에서 잠시 언급한 LLaMA는 PaLM의 1/8 수준인 65B 크기의 모델로<br>\n",
    "PaLM이 학습한 토큰의 두배를 넘는 1.4T 개의 토큰을 학습하여 훨씬 더 좋은 성능을 냈다는 사실을 기억해주세요.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LM이 풀기 가장 까다로운 문제 중에 하나는 다단계의 추론을 통해 답변을 도출해내야 하는 형식의 문제입니다.<br>\n",
    "2021년 DeepMind에서 발표한 LLM인 Gopher에서는 단순히 모델 사이즈를 키우는 것만으로<br>\n",
    "논리적, 수학적 추론이 필요한 문제를 잘 풀어내기가 어렵다고 토로하고 있습니다. [참고](https://arxiv.org/pdf/2112.11446.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaLM은 280B 짜리 모델인 Gopher 보다 2배 이상 큰 모델입니다.<br>\n",
    "Deepmind와 달리 Google의 연구진은 \"chain-of-thought\" (이하 CoT) 이라는 prompting 기법을 PaLM에 사용하여<br>\n",
    "Gopher가 어려움을 겪은 Multi-step reasoning에서 좋은 성능을 낼 수 있음을 보여주었습니다.<br>\n",
    "Multi-step reasoning 문제의 대표적인 예로는<br>\n",
    "Arithmetic reasoning(산술추론)과 Commonsense reasoning(상식추론) 이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "산술추론은 아래 그림의 왼쪽 예제처럼 두 단계 이상의 추론을 거쳐야 풀 수 있는 산술문제를 가리킵니다.<br>\n",
    "상식추론은 우리가 살고 있는 세계에 대한 일반지식으로 적절히 추론해야 하는 문제를 가리킵니다.<br>\n",
    "예컨대 \"집에 서둘러 가려고 했지만 신호등이 노란색으로 바뀌었다. 어떻게 해야할까?\" 라는 질문에<br>\n",
    "모델은 (a) \"기다리십시오\" (b) \"무단횡단을 하십시오\" (c) \"바다로 가십시오\" 등의 옵션에서<br>\n",
    "하나를 선택해야 하는 문제를 풀어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 chain-of-thought prompting 의 원리는 이렇습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2204.02311.pdf](../Images/lec_25/13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림의 왼쪽에서 볼 수 있듯이, LLM에 일반적인 few-shot learning을 시키면 모델이 잘못된 답을 내곤 합니다.<br>\n",
    "그러나 모델에게 prompt를 줄 때 문제에 대한 답을 바로 주는 게 아니라<br>\n",
    "문제를 푸는데 필요한 사고과정을 함께 준 뒤 유사한 문제를 풀게 시키면<br>\n",
    "놀랍게도 그 문제에 대한 답만 맞추는 게 아니라, 자신이 풀이한 과정까지 답변에 포함시켜 돌려주는 걸 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chain-of-thought prompting의 의의는, 모델의 추론결과를 토대로 오류분석이 가능해지고,<br>\n",
    "모델이 왜 그렇게 추론했는지에 대한 해석가능성을 높일 수 있다는 데 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaLM과 같은 LLM에 chain-of-thought prompting을 했을 때<br>\n",
    "얼마나 놀라운 언어능력이 emergent 되는지 엿볼 수 있는 사례 하나를 논문에서 인용해보겠습니다.<br>\n",
    "모델에게 농담하나를 들려주고,<br>\n",
    "그것이 왜 농담으로 해석될 수 있는지에 대한 설명과 함께, 농담으로 해석될 수 있는 문장을 input으로 주었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I will explain these jokes: \"Always borrow money from a pessimist. They’ll never expect it back.\"<br><br>\n",
    "> Explanation: Most people expect you to pay them back when you borrow money,\n",
    "however a pessimist is someone who always assumes the worst,\n",
    "so if you borrow money from them, they will expect that you won't pay them back anyways.<br><br>\n",
    "> Input: I tried 10,000 random restarts of my neural network,\n",
    "but I was accused of overfitting. I guess no good seed goes unpunished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가히 놀라운 언어 이해 능력입니다.<br>\n",
    "언어모델을 만들어보신 분들은 LM이 사람의 농담을 이해하고 그 농담에 대한 해석까지 해줄 수 있게 만드는 것이<br>\n",
    "얼마나 어려운 일인지 아실텐데요, 심지어 저 농담은 신경망 학습과 오버피팅의 의미, 그리고 언어유희까지 이해했을 때야<br>\n",
    "비로소 농담으로 해석될 수 있는 수준 높은 농담이기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이밖에도 PaLM은 번역, 요약, 질문답변 등 주요 NLP task에서 이전 모델들을 넘어섰고,<br>\n",
    "다국어로 해당 task를 수행했을 때도 더 좋은 성능을 냈습니다.<br>\n",
    "이렇게 강력한 LLM이다보니 PaLM은 윤리적으로 문제가 될 수 있는 문장역시 더 잘 생성해냈고,<br>\n",
    "연구진들은 이에 대해 추가 연구의 필요성을 언급했습니다.<br>\n",
    "(이 문제는 step4에서 좀 더 깊이 있게 다뤄보겠습니다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떠신가요?\n",
    "<br><br>\n",
    "LLM의 instruction following과 multi-step reasoning 능력에 대해 감을 좀 잡으셨나요?<br>\n",
    "그런데 PaLM의 CoT를 보면서 이런 궁금증이 들지는 않으셨나요?<br>\n",
    "**\"PaLM 같은 540B 사이즈 전후의 초거대 모델에서만 CoT가 먹히는 걸까?\"**<br>\n",
    "**\"그보다 훨씬 작은 모델에서 CoT prompting은 불가능한 것일까?\"**<br>\n",
    "<br>\n",
    "다음 스텝에서 이제 본격적으로 LLM의 emergent abilities 에 대해 알아보면서 위 질문에 답을 찾아보도록 합시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-3. LLM + Emergent Abilities = AGI?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Emergent Abilities의 정의**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emergence(창발)이란 철학과 과학에서 오랜 역사를 지닌 복잡한 개념입니다. [(참고)](https://en.wikipedia.org/wiki/Emergence)\n",
    "<br><br>\n",
    "위키에서 볼 수 있듯이 창발에 대한 수많은 정의와 해석이 있지만<br>\n",
    "우리는 노벨물리학상 수상자인 Philip Anderson가 1972년에 발표한 에세이<br>\n",
    "\"More Is Different\" 에서 정의한 창발의 개념을 가지고 접근해보겠습니다.\n",
    "<br><br>\n",
    "**\"Emergence is when quantitative changes in a system result in qualitative changes in behavior.\"**\n",
    "<br><br>\n",
    "번역하자면 **\"Emergence(창발)은 시스템에서의 양적변화가 질적변화를 가져올 때를 의미한다\"** 정도가 되겠네요.\n",
    "<br><br>\n",
    "우리는 앞선 스텝에서<br>\n",
    "파라미터 스케일의 급진적인 변화가 가져온 모델 추론 능력의 질적인 변화의 예시들을 살펴보았습니다.<br>\n",
    "주요 LLM을 개발해온 Google과 DeepMind 그리고 유수 대학 연구자들은<br>\n",
    "2022년 10월 [Emergent Abilities of Large Language Models](https://arxiv.org/pdf/2206.07682.pdf) 이라는 논문을 발표했습니다.\n",
    "<br><br>\n",
    "연구진은 LLM의 Emergent Abilities를 소규모 모델에는 없지만 대규모 모델에는 존재하는 능력으로 정의합니다.<br>\n",
    "따라서 Emergence는 모델 파라미터 수로 측정된 모델 규모와 관련지어 집니다.\n",
    "<br><br>\n",
    "아래 그림은 task별 모델의 성능과 모델 파라미터 개수 사이의 관계에서\n",
    "Emergence가 나타나는 패턴을 보여주는 그래프입니다.\n",
    "모두 단순한 few-shot prompting 에서의 Emergence를 나타냅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2206.07682.pdf](../Images/lec_25/14.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 : A, B, C, D 는 BIG-Bench, (출처 : https://github.com/google/BIG-bench)\n",
    "E는 TruthfulQA benchmark,<br>\n",
    "F는 Grounded conceptual mappings,<br>\n",
    "G는 Massive Multi-task Language Understanding (MMLU) benchmark,<br>\n",
    "H는 (WiC) benchmark 입니다.<br>\n",
    "F에 관해선 [논문 Mapping Language Models To Grounded Conceptual Spaces](https://openreview.net/pdf?id=gJcEM8sxHK)을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**모델 크기가 특정 임계값을 넘어서는 순간 모델 performance가 확연히 달라지는 걸 볼 수 있습니다.**<br>\n",
    "우리는 이 패턴을 일종의 scaling law로 해석해볼 수 있습니다. 무어의 법칙처럼 말이죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![출처 : https://arxiv.org/pdf/2206.07682.pdf](../Images/lec_25/15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. LLM + Emergent Abilities = AGI?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-4. InstructGPT : RLHF, 언어모델과 강화학습의 만남**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-5. GPT-4 vs LLaMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **25-6. 마무리하며**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
